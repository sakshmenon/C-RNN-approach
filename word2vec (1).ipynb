{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX4n9TsbGw-f"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:27.931202Z",
     "iopub.status.busy": "2023-12-07T12:19:27.930979Z",
     "iopub.status.idle": "2023-12-07T12:19:27.934973Z",
     "shell.execute_reply": "2023-12-07T12:19:27.934373Z"
    },
    "id": "0nbI5DtDGw-i"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/word2vec\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/word2vec.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/word2vec.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/word2vec.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haJUNjSB60Kh"
   },
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99d4ky2lWFvn"
   },
   "source": [
    "word2vec is not a singular algorithm, rather, it is a family of model architectures and optimizations that can be used to learn word embeddings from large datasets. Embeddings learned through word2vec have proven to be successful on a variety of downstream natural language processing tasks.\n",
    "\n",
    "Note: This tutorial is based on [Efficient estimation of word representations in vector space](https://arxiv.org/pdf/1301.3781.pdf) and [Distributed representations of words and phrases and their compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf). It is not an exact implementation of the papers. Rather, it is intended to illustrate the key ideas.\n",
    "\n",
    "These papers proposed two methods for learning representations of words:\n",
    "\n",
    "*   **Continuous bag-of-words model**: predicts the middle word based on surrounding context words. The context consists of a few words before and after the current (middle) word. This architecture is called a bag-of-words model as the order of words in the context is not important.\n",
    "*   **Continuous skip-gram model**: predicts words within a certain range before and after the current word in the same sentence. A worked example of this is given below.\n",
    "\n",
    "You'll use the skip-gram approach in this tutorial. First, you'll explore skip-grams and other concepts using a single sentence for illustration. Next, you'll train your own word2vec model on a small dataset. This tutorial also contains code to export the trained embeddings and visualize them in the [TensorFlow Embedding Projector](http://projector.tensorflow.org/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xP00WlaMWBZC"
   },
   "source": [
    "## Skip-gram and negative sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr2wjv0bW236"
   },
   "source": [
    "While a bag-of-words model predicts a word given the neighboring context, a skip-gram model predicts the context (or neighbors) of a word, given the word itself. The model is trained on skip-grams, which are n-grams that allow tokens to be skipped (see the diagram below for an example). The context of a word can be represented through a set of skip-gram pairs of `(target_word, context_word)` where `context_word` appears in the neighboring context of `target_word`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICjc-McbaVTd"
   },
   "source": [
    "Consider the following sentence of eight words:\n",
    "\n",
    "> The wide road shimmered in the hot sun.\n",
    "\n",
    "The context words for each of the 8 words of this sentence are defined by a window size. The window size determines the span of words on either side of a `target_word` that can be considered a `context word`. Below is a table of skip-grams for target words based on different window sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKE87IKT_YT8"
   },
   "source": [
    "Note: For this tutorial, a window size of `n` implies n words on each side with a total window span of 2*n+1 words across a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsCwQ07E8mqU"
   },
   "source": [
    "![word2vec_skipgrams](https://tensorflow.org/text/tutorials/images/word2vec_skipgram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK1gN1jwkMpU"
   },
   "source": [
    "The training objective of the skip-gram model is to maximize the probability of predicting context words given the target word. For a sequence of words *w<sub>1</sub>, w<sub>2</sub>, ... w<sub>T</sub>*, the objective can be written as the average log probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pILO_iAc84e-"
   },
   "source": [
    "![word2vec_skipgram_objective](https://tensorflow.org/text/tutorials/images/word2vec_skipgram_objective.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsy6TUbtnz_K"
   },
   "source": [
    "where `c` is the size of the training context. The basic skip-gram formulation defines this probability using the softmax function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P81Qavbb9APd"
   },
   "source": [
    "![word2vec_full_softmax](https://tensorflow.org/text/tutorials/images/word2vec_full_softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axZvd-hhotVB"
   },
   "source": [
    "where *v* and *v<sup>'<sup>* are target and context vector representations of words and *W* is vocabulary size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoLzxbqSpT6_"
   },
   "source": [
    "Computing the denominator of this formulation involves performing a full softmax over the entire vocabulary words, which are often large (10<sup>5</sup>-10<sup>7</sup>) terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5VWYtmFzHkU"
   },
   "source": [
    "The [noise contrastive estimation](https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss) (NCE) loss function is an efficient approximation for a full softmax. With an objective to learn word embeddings instead of modeling the word distribution, the NCE loss can be [simplified](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) to use negative sampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTZBPf1RsOsg"
   },
   "source": [
    "The simplified negative sampling objective for a target word is to distinguish  the context word from `num_ns` negative samples drawn from noise distribution *P<sub>n</sub>(w)* of words. More precisely, an efficient approximation of full softmax over the vocabulary is, for a skip-gram pair, to pose the loss for a target word as a classification problem between the context word and `num_ns` negative samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cl0rSfHjt6Mf"
   },
   "source": [
    "A negative sample is defined as a `(target_word, context_word)` pair such that the `context_word` does not appear in the `window_size` neighborhood of the `target_word`. For the example sentence, these are a few potential negative samples (when `window_size` is `2`).\n",
    "\n",
    "```\n",
    "(hot, shimmered)\n",
    "(wide, hot)\n",
    "(wide, sun)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kq0q2uqbucFg"
   },
   "source": [
    "In the next section, you'll generate skip-grams and negative samples for a single sentence. You'll also learn about subsampling techniques and train a classification model for positive and negative training examples later in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk4-Hpe1CH16"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:27.940359Z",
     "iopub.status.busy": "2023-12-07T12:19:27.939794Z",
     "iopub.status.idle": "2023-12-07T12:19:30.377298Z",
     "shell.execute_reply": "2023-12-07T12:19:30.376504Z"
    },
    "id": "RutaI-Tpev3T"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 14:53:59.062958: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-22 14:53:59.134703: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-22 14:53:59.134743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-22 14:53:59.139028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-22 14:53:59.156155: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-22 14:53:59.156671: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-22 14:54:01.581395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.381719Z",
     "iopub.status.busy": "2023-12-07T12:19:30.380983Z",
     "iopub.status.idle": "2023-12-07T12:19:30.389724Z",
     "shell.execute_reply": "2023-12-07T12:19:30.389128Z"
    },
    "id": "10pyUMFkGKVQ"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.392994Z",
     "iopub.status.busy": "2023-12-07T12:19:30.392583Z",
     "iopub.status.idle": "2023-12-07T12:19:30.395835Z",
     "shell.execute_reply": "2023-12-07T12:19:30.395266Z"
    },
    "id": "XkJ5299Tek6B"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW-g5buCHwh3"
   },
   "source": [
    "### Vectorize an example sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8TfZIgoQrcP"
   },
   "source": [
    "Consider the following sentence:\n",
    "\n",
    "> The wide road shimmered in the hot sun.\n",
    "\n",
    "Tokenize the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.399597Z",
     "iopub.status.busy": "2023-12-07T12:19:30.399001Z",
     "iopub.status.idle": "2023-12-07T12:19:30.402860Z",
     "shell.execute_reply": "2023-12-07T12:19:30.402229Z"
    },
    "id": "bsl7jBzV6_KK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU-bs1XtThEw"
   },
   "source": [
    "Create a vocabulary to save mappings from tokens to integer indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.406204Z",
     "iopub.status.busy": "2023-12-07T12:19:30.405637Z",
     "iopub.status.idle": "2023-12-07T12:19:30.410018Z",
     "shell.execute_reply": "2023-12-07T12:19:30.409358Z"
    },
    "id": "UdYv1HJUQ8XA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n"
     ]
    }
   ],
   "source": [
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for token in tokens:\n",
    "  if token not in vocab:\n",
    "    vocab[token] = index\n",
    "    index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpuP43Dddasr"
   },
   "source": [
    "Create an inverse vocabulary to save mappings from integer indices to tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.413419Z",
     "iopub.status.busy": "2023-12-07T12:19:30.412870Z",
     "iopub.status.idle": "2023-12-07T12:19:30.416605Z",
     "shell.execute_reply": "2023-12-07T12:19:30.416001Z"
    },
    "id": "o9ULAJYtEvKl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3qtuyxIRyii"
   },
   "source": [
    "Vectorize your sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.420194Z",
     "iopub.status.busy": "2023-12-07T12:19:30.419615Z",
     "iopub.status.idle": "2023-12-07T12:19:30.423260Z",
     "shell.execute_reply": "2023-12-07T12:19:30.422619Z"
    },
    "id": "CsB3-9uQQYyl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ox1I28JRIOdM"
   },
   "source": [
    "### Generate skip-grams from one sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7NNKAmSiHvy"
   },
   "source": [
    "The `tf.keras.preprocessing.sequence` module provides useful functions that simplify data preparation for word2vec. You can use the `tf.keras.preprocessing.sequence.skipgrams` to generate skip-gram pairs from the `example_sequence` with a given `window_size` from tokens in the range `[0, vocab_size)`.\n",
    "\n",
    "Note: `negative_samples` is set to `0` here, as batching negative samples generated by this function requires a bit of code. You will use another function to perform negative sampling in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.426796Z",
     "iopub.status.busy": "2023-12-07T12:19:30.426167Z",
     "iopub.status.idle": "2023-12-07T12:19:30.430632Z",
     "shell.execute_reply": "2023-12-07T12:19:30.429971Z"
    },
    "id": "USAJxW4RD7pn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0)\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc9uhiMwY-AQ"
   },
   "source": [
    "Print a few positive skip-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.433884Z",
     "iopub.status.busy": "2023-12-07T12:19:30.433305Z",
     "iopub.status.idle": "2023-12-07T12:19:30.437077Z",
     "shell.execute_reply": "2023-12-07T12:19:30.436468Z"
    },
    "id": "SCnqEukIE9pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5): (road, in)\n",
      "(1, 4): (the, shimmered)\n",
      "(5, 4): (in, shimmered)\n",
      "(7, 1): (sun, the)\n",
      "(2, 1): (wide, the)\n"
     ]
    }
   ],
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ua9PkMTISF0"
   },
   "source": [
    "### Negative sampling for one skip-gram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Esqn8WBfZnEK"
   },
   "source": [
    "The `skipgrams` function returns all positive skip-gram pairs by sliding over a given window span. To produce additional skip-gram pairs that would serve as negative samples for training, you need to sample random words from the vocabulary. Use the `tf.random.log_uniform_candidate_sampler` function to sample `num_ns` number of negative samples for a given target word in a window. You can call the function on one skip-grams's target word and pass the context word as true class to exclude it from being sampled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgH3aSvw3xTD"
   },
   "source": [
    "Key point: `num_ns` (the number of negative samples per a positive context word) in the `[5, 20]` range is [shown to work](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) best for smaller datasets, while `num_ns` in the `[2, 5]` range suffices for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:30.440518Z",
     "iopub.status.busy": "2023-12-07T12:19:30.440119Z",
     "iopub.status.idle": "2023-12-07T12:19:32.816463Z",
     "shell.execute_reply": "2023-12-07T12:19:32.815725Z"
    },
    "id": "m_LmdzqIGr5L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)\n",
      "['wide', 'the', 'shimmered', 'road']\n"
     ]
    }
   ],
   "source": [
    "# Get target and context words for one positive skip-gram.\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Set the number of negative samples per positive context.\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
    "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,  # number of negative context words to sample\n",
    "    unique=True,  # all the negative samples should be unique\n",
    "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
    "    seed=SEED,  # seed for reproducibility\n",
    "    name=\"negative_sampling\"  # name of this operation\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MSxWCrLIalp"
   },
   "source": [
    "### Construct one training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6uEWdj8vKKv"
   },
   "source": [
    "For a given positive `(target_word, context_word)` skip-gram, you now also have `num_ns` negative sampled context words that do not appear in the window size neighborhood of `target_word`. Batch the `1` positive `context_word` and `num_ns` negative context words into one tensor. This produces a set of positive skip-grams (labeled as `1`) and negative samples (labeled as `0`) for each target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:32.820075Z",
     "iopub.status.busy": "2023-12-07T12:19:32.819823Z",
     "iopub.status.idle": "2023-12-07T12:19:32.827221Z",
     "shell.execute_reply": "2023-12-07T12:19:32.826559Z"
    },
    "id": "zSiZwifuLvHf"
   },
   "outputs": [],
   "source": [
    "# Reduce a dimension so you can use concatenation (in the next step).\n",
    "squeezed_context_class = tf.squeeze(context_class, 1)\n",
    "\n",
    "# Concatenate a positive context word with negative sampled words.\n",
    "context = tf.concat([squeezed_context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "# Label the first context word as `1` (positive) followed by `num_ns` `0`s (negative).\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "target = target_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIJeoFCAwtXJ"
   },
   "source": [
    "Check out the context and the corresponding labels for the target word from the skip-gram example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:32.830680Z",
     "iopub.status.busy": "2023-12-07T12:19:32.830444Z",
     "iopub.status.idle": "2023-12-07T12:19:32.837336Z",
     "shell.execute_reply": "2023-12-07T12:19:32.836694Z"
    },
    "id": "tzyCPCuZwmdL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 3\n",
      "target_word     : road\n",
      "context_indices : [5 2 1 4 3]\n",
      "context_words   : ['in', 'wide', 'the', 'shimmered', 'road']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBtTcUVQr8EO"
   },
   "source": [
    "A tuple of `(target, context, label)` tensors constitutes one training example for training your skip-gram negative sampling word2vec model. Notice that the target is of shape `(1,)` while the context and label are of shape `(1+num_ns,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:32.840524Z",
     "iopub.status.busy": "2023-12-07T12:19:32.840295Z",
     "iopub.status.idle": "2023-12-07T12:19:32.844249Z",
     "shell.execute_reply": "2023-12-07T12:19:32.843638Z"
    },
    "id": "x-FwkR8jx9-Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  : 3\n",
      "context : tf.Tensor([5 2 1 4 3], shape=(5,), dtype=int64)\n",
      "label   : tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"target  :\", target)\n",
    "print(\"context :\", context)\n",
    "print(\"label   :\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bRJIlow4Dlv"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWkuha0oykG5"
   },
   "source": [
    "This diagram summarizes the procedure of generating a training example from a sentence:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KlwdiAa9crJ"
   },
   "source": [
    "![word2vec_negative_sampling](https://tensorflow.org/text/tutorials/images/word2vec_negative_sampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37e53f07f67c"
   },
   "source": [
    "Notice that the words `temperature` and `code` are not part of the input sentence. They belong to the vocabulary like certain other indices used in the diagram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wmdO_MEIpaM"
   },
   "source": [
    "## Compile all steps into one function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLKwNAczHsKg"
   },
   "source": [
    "### Skip-gram sampling table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUUK3uDtFNFE"
   },
   "source": [
    "A large dataset means larger vocabulary with higher number of more frequent words such as stopwords. Training examples obtained from sampling commonly occurring words (such as `the`, `is`, `on`) don't add much useful information  for the model to learn from. [Mikolov et al.](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) suggest subsampling of frequent words as a helpful practice to improve embedding quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPtbv7zNP7Dx"
   },
   "source": [
    "The `tf.keras.preprocessing.sequence.skipgrams` function accepts a sampling table argument to encode probabilities of sampling any token. You can use the `tf.keras.preprocessing.sequence.make_sampling_table` to  generate a word-frequency rank based probabilistic sampling table and pass it to the `skipgrams` function. Inspect the sampling probabilities for a `vocab_size` of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:32.848709Z",
     "iopub.status.busy": "2023-12-07T12:19:32.848455Z",
     "iopub.status.idle": "2023-12-07T12:19:32.852863Z",
     "shell.execute_reply": "2023-12-07T12:19:32.852185Z"
    },
    "id": "Rn9zAnDccyRg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHvSptcPk5fp"
   },
   "source": [
    "`sampling_table[i]` denotes the probability of sampling the i-th most common word in a dataset. The function assumes a [Zipf's distribution](https://en.wikipedia.org/wiki/Zipf%27s_law) of the word frequencies for sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRHMssMmHgH-"
   },
   "source": [
    "Key point: The `tf.random.log_uniform_candidate_sampler` already assumes that the vocabulary frequency follows a log-uniform (Zipf's) distribution. Using these distribution weighted sampling also helps approximate the Noise Contrastive Estimation (NCE) loss with simpler loss functions for training a negative sampling objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj--8RFK6fgW"
   },
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy5hl4lQ0B2M"
   },
   "source": [
    "Compile all the steps described above into a function that can be called on a list of vectorized sentences obtained from any text dataset. Notice that the sampling table is built before sampling skip-gram word pairs. You will use this function in the later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:32.856574Z",
     "iopub.status.busy": "2023-12-07T12:19:32.856043Z",
     "iopub.status.idle": "2023-12-07T12:19:32.863099Z",
     "shell.execute_reply": "2023-12-07T12:19:32.862495Z"
    },
    "id": "63INISDEX1Hu"
   },
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "  # Elements of each training example are appended to these lists.\n",
    "  targets, contexts, labels = [], [], []\n",
    "\n",
    "  # Build the sampling table for `vocab_size` tokens.\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Iterate over all sequences (sentences) in the dataset.\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0)\n",
    "\n",
    "    # Iterate over each positive skip-gram pair to produce training examples\n",
    "    # with a positive context word and negative samples.\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "      context_class = tf.expand_dims(\n",
    "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1,\n",
    "          num_sampled=num_ns,\n",
    "          unique=True,\n",
    "          range_max=vocab_size,\n",
    "          seed=seed,\n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      # Build context and label vectors (for one target word)\n",
    "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
    "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      # Append each element from the training example to global lists.\n",
    "      targets.append(target_word)\n",
    "      contexts.append(context)\n",
    "      labels.append(label)\n",
    "\n",
    "  return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shvPC8Ji2cMK"
   },
   "source": [
    "## Prepare training data for word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5mbZsZu6uKg"
   },
   "source": [
    "With an understanding of how to work with one sentence for a skip-gram negative sampling based word2vec model, you can proceed to generate training examples from a larger list of sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFlikI6L26nh"
   },
   "source": [
    "### Download text corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEFavOgN98al"
   },
   "source": [
    "You will use a text file of Shakespeare's writing for this tutorial. Change the following line to run this code on your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:32.866556Z",
     "iopub.status.busy": "2023-12-07T12:19:32.866309Z",
     "iopub.status.idle": "2023-12-07T12:19:32.950643Z",
     "shell.execute_reply": "2023-12-07T12:19:32.949988Z"
    },
    "id": "QFkitxzVVaAi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOsbLq8a37dr"
   },
   "source": [
    "Read the text from the file and print the first few lines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:32.954086Z",
     "iopub.status.busy": "2023-12-07T12:19:32.953841Z",
     "iopub.status.idle": "2023-12-07T12:19:32.963265Z",
     "shell.execute_reply": "2023-12-07T12:19:32.962681Z"
    },
    "id": "lfgnsUw3ofMD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as f:\n",
    "  lines = f.read().splitlines()\n",
    "for line in lines[:20]:\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTNZYqUs5C2V"
   },
   "source": [
    "Use the non empty lines to construct a `tf.data.TextLineDataset` object for the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:32.966404Z",
     "iopub.status.busy": "2023-12-07T12:19:32.966115Z",
     "iopub.status.idle": "2023-12-07T12:19:33.001698Z",
     "shell.execute_reply": "2023-12-07T12:19:33.001072Z"
    },
    "id": "ViDrwy-HjAs9"
   },
   "outputs": [],
   "source": [
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfsc88zE9upk"
   },
   "source": [
    "### Vectorize sentences from the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfgZo8zR94KK"
   },
   "source": [
    "You can use the `TextVectorization` layer to vectorize sentences from the corpus. Learn more about using this layer in this [Text classification](https://www.tensorflow.org/tutorials/keras/text_classification) tutorial. Notice from the first few sentences above that the text needs to be in one case and punctuation needs to be removed. To do this, define a `custom_standardization function` that can be used in the TextVectorization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:33.005786Z",
     "iopub.status.busy": "2023-12-07T12:19:33.005525Z",
     "iopub.status.idle": "2023-12-07T12:19:33.021853Z",
     "shell.execute_reply": "2023-12-07T12:19:33.021180Z"
    },
    "id": "2MlsXzo-ZlfK"
   },
   "outputs": [],
   "source": [
    "# Now, create a custom standardization function to lowercase the text and\n",
    "# remove punctuation.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Define the vocabulary size and the number of words in a sequence.\n",
    "vocab_size = 4096\n",
    "sequence_length = 10\n",
    "\n",
    "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
    "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
    "# same length.\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g92LuvnyBmz1"
   },
   "source": [
    "Call `TextVectorization.adapt` on the text dataset to create vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:33.025694Z",
     "iopub.status.busy": "2023-12-07T12:19:33.025064Z",
     "iopub.status.idle": "2023-12-07T12:19:34.145474Z",
     "shell.execute_reply": "2023-12-07T12:19:34.144595Z"
    },
    "id": "seZau_iYMPFT"
   },
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jg2z7eeHMnH-"
   },
   "source": [
    "Once the state of the layer has been adapted to represent the text corpus, the vocabulary can be accessed with `TextVectorization.get_vocabulary`. This function returns a list of all vocabulary tokens sorted (descending) by their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:34.149647Z",
     "iopub.status.busy": "2023-12-07T12:19:34.149371Z",
     "iopub.status.idle": "2023-12-07T12:19:34.160202Z",
     "shell.execute_reply": "2023-12-07T12:19:34.159615Z"
    },
    "id": "jgw9pTA7MRaU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"
     ]
    }
   ],
   "source": [
    "# Save the created vocabulary for reference.\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOQ30Tx6KA2G"
   },
   "source": [
    "The `vectorize_layer` can now be used to generate vectors for each element in the `text_ds` (a `tf.data.Dataset`). Apply `Dataset.batch`, `Dataset.prefetch`, `Dataset.map`, and `Dataset.unbatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:34.163645Z",
     "iopub.status.busy": "2023-12-07T12:19:34.163175Z",
     "iopub.status.idle": "2023-12-07T12:19:34.208014Z",
     "shell.execute_reply": "2023-12-07T12:19:34.207293Z"
    },
    "id": "yUVYrDp0araQ"
   },
   "outputs": [],
   "source": [
    "# Vectorize the data in text_ds.\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YyH_SYzB72p"
   },
   "source": [
    "### Obtain sequences from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFUQLX0_KaRC"
   },
   "source": [
    "You now have a `tf.data.Dataset` of integer encoded sentences. To prepare the dataset for training a word2vec model, flatten the dataset into a list of sentence vector sequences. This step is required as you would iterate over each sentence in the dataset to produce positive and negative examples.\n",
    "\n",
    "Note: Since the `generate_training_data()` defined earlier uses non-TensorFlow Python/NumPy functions, you could also use a `tf.py_function` or `tf.numpy_function` with `tf.data.Dataset.map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:34.211746Z",
     "iopub.status.busy": "2023-12-07T12:19:34.211155Z",
     "iopub.status.idle": "2023-12-07T12:19:37.810953Z",
     "shell.execute_reply": "2023-12-07T12:19:37.810245Z"
    },
    "id": "sGXoOh9y11pM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32777\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDc4riukLTqg"
   },
   "source": [
    "Inspect a few examples from `sequences`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:37.814472Z",
     "iopub.status.busy": "2023-12-07T12:19:37.814232Z",
     "iopub.status.idle": "2023-12-07T12:19:37.818723Z",
     "shell.execute_reply": "2023-12-07T12:19:37.818030Z"
    },
    "id": "WZf1RIbB2Dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
      "[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n",
      "[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n",
      "[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences[:5]:\n",
    "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([138,  36, 982, 144, 673, 125,  16, 106,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([106, 106,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   7,   41,   34, 1286,  344,    4,  200,   64,    4, 3690]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1286, 1286,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  89,    7,   93, 1187,  225,   12, 2442,  592,    4,    2]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  36, 2655,   36, 2655,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  72,   79,  506,   27,    3,   56,   24, 1390,   57,   40]),\n",
       " array([644,   9,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  32,   54, 2863,  885,   72,   17,   18,  163,  146,  146]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 74, 218,  46, 595,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,   41,    1,  172,  595,    2, 1780,   46,    0,    0]),\n",
       " array([  29, 1323,    1,   47,   58,    1,   79,   39,   60,    0]),\n",
       " array([ 58, 573,  79,  22,   2,   1, 334,  17,  76,   0]),\n",
       " array([1870,   36,  258, 1026,   60,    1,   79,    1,    0,    0]),\n",
       " array([ 22,  60, 131,  36,  41, 100, 267,   2,   1,  10]),\n",
       " array([   1,   79,    2, 2346,    6,   40, 1540,   12,   25,   88]),\n",
       " array([ 1,  4,  1, 65,  1, 40,  0,  0,  0,  0]),\n",
       " array([2871,   12,    9, 1375,    4,   66,   72,   79,  625,   21]),\n",
       " array([ 40,   1, 251,  36, 662,   1,  14,   2, 260,  93]),\n",
       " array([ 106,   21,   11,    1,   14, 2461,   13,   11, 3329,   14]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  58,    7,  982, 3696,  170, 1187,  225,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 170,   27,   89,  339,    9,  157, 1033,    4,    2,    1]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1834,    7,   29, 1519,   23,  320,  163,   14,   20,  659]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([157,  56,   3, 231,  18, 496,   4, 102,  27,  46]),\n",
       " array([ 556, 1169,   22,   10,   23, 3500,  245,   15,  145,  450]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181,  22, 106,  13,   1,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  71, 214,   7,  29,  23,  70, 163,   1,  23]),\n",
       " array([ 17,   4,  10, 384, 171,   1, 153, 115,  18,   0]),\n",
       " array([496,   4,  71,  17,  59,  14,  20, 659,  23,  95]),\n",
       " array([ 303,   20,  223,    3,    4,   18, 1781,  450,   53,   23]),\n",
       " array([ 12, 196, 184,   2,   1,   6,  20, 638,   0,   0]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,   23,  142,  309,   11,   20,  408,    7, 1199,    9]),\n",
       " array([1206,   11,   27,    7,   86,   11,   32,  177,   71,   23]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  39,    5,   86,   13,    5,  451,   13,   18, 2022,    6]),\n",
       " array([  23,   70,  742,   15,    1,    4, 3322,   11, 3431,    0]),\n",
       " array([  29, 4083,   41,  104,    2,  205,  649,   48,    2,  445]),\n",
       " array([  12,    1,   90,  188,   36, 2956,   62,    4,    2, 1319]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([49, 49,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([752, 103, 194,  62,   0,   0,   0,   0,   0,   0]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 446,  154,    1,   74,   10,   70, 1196,  712,    0,    0]),\n",
       " array([  2, 307,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([339,  74, 605, 394,  58,  34,   2, 257,  76,  28]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,    1,    8, 2208,   11,  158,   97,   75,    7,    0]),\n",
       " array([ 15,   1,   3,   1,   2, 390, 106,   5, 160,   7]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  40,  388,   12,   13, 1504,    4,    2, 1520,   60,   24]),\n",
       " array([  92,    1,   21,    1,   29,   36, 1368,    4,   42,    0]),\n",
       " array([ 53,  44,  56, 315, 847,  11, 780,  60,  71, 172]),\n",
       " array([2089,   24,  751,    1,   60,   37,   93,   36,    0,    0]),\n",
       " array([ 24, 751, 395, 100,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  90,  628,    8,   46,  208,  109,  605, 1942,    0,    0]),\n",
       " array([  31,    7, 2840,  969,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,  142,   51,   36,   41, 1268,  702,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 117,   7, 208, 120,   1, 497,   0,   0,   0]),\n",
       " array([  24,    2, 1780,    6,    7,   14,   19, 1610,    0,    0]),\n",
       " array([  19, 2870,   11,   21, 3136,    7,   78,   25,   56,    0]),\n",
       " array([ 537,   57,    2,  182,   15,   19,    1,   25, 1954,   66]),\n",
       " array([170,   2, 820, 329, 202, 690,  31,  47,   0,   0]),\n",
       " array([   2,  177,   17, 1623, 3150,  610,  352,    1,    0,    0]),\n",
       " array([  6,  54, 751,   1,   1,  64, 115, 195,   0,   0]),\n",
       " array([ 787,   11,   19, 3612,   14,    2, 3136,    0,    0,    0]),\n",
       " array([   2,  260,   13,    2, 1780,   80,   17,    3,    0,    0]),\n",
       " array([ 19, 987,   4,  66,  13, 395,  86, 309, 833,   0]),\n",
       " array([   7,   41, 3314,   33, 3193,    0,    0,    0,    0,    0]),\n",
       " array([ 770,   97,   54,    1,    7,    3,    7, 1346,    0,    0]),\n",
       " array([  2,   1,  48,   2, 329, 103, 497,  14,   7,  84]),\n",
       " array([ 73,   7, 699,  66,  25, 658,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([497,  14,  79, 139, 310,  60, 439,   1,  14,  79]),\n",
       " array([  82, 1052,   79,    4, 3690,    3,   65,    1,    0,    0]),\n",
       " array([   1,   15, 2402,   80,    1,   14,    1,    4,    0,    0]),\n",
       " array([3347,    1, 3432, 1830,  144, 1870,  968,    0,    0,    0]),\n",
       " array([   1,  170,    2,  683,    3, 2322,   54,    0,    0,    0]),\n",
       " array([2336, 2883, 1830,    4,    1,  111,    3,    1,    0,    0]),\n",
       " array([   2,  172,   39,    2,  664, 1126,   79,   13,  111,   60]),\n",
       " array([413,  34,   2,  77,  60, 203,  79,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([478,   7,  86,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 691,  969, 1729,    1,    0,    0,    0,    0,    0,    0]),\n",
       " array([  52,   18, 1861,    6, 1696,    5,   37,  117,    7,    0]),\n",
       " array([  9, 798, 639,  17,  78,  18,   7,  24, 311,  17]),\n",
       " array([  22,  228,   17, 1636,    8,  502,    5,   31, 2834,    0]),\n",
       " array([   4, 2279,  818,    9,  234,   54,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 56,  67, 125,  17,  51,  82,   7,  86,  13, 131]),\n",
       " array([   1,  219,   40, 1991,   15,    9,  639,   22,   88,  818]),\n",
       " array([  7, 959,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  85,   59,    9,  118,   73,   34,    2, 1842, 2636,    0]),\n",
       " array([   1,  170,    2, 1490,  141, 1861,   17,    0,    0,    0]),\n",
       " array([  10,  337,   84,    9, 3643,   17,   95, 1016,    0,    0]),\n",
       " array([   5,    2, 3002,   48,    2,  407, 1119,    3,    1,    0]),\n",
       " array([ 227,    1,    2,    1,  134, 1597,    0,    0,    0,    0]),\n",
       " array([  84, 1072,   15,    2,  257,   97,    2,  205, 1681,    0]),\n",
       " array([  95,   98,    3,  125, 1384, 1683, 1007,  808,    0,    0]),\n",
       " array([   3,    1,    1,   95, 1670,    0,    0,    0,    0,    0]),\n",
       " array([ 214,    2, 2031,    3, 1198,  572,    0,    0,    0,    0]),\n",
       " array([   6,    2, 1329,  407,    2, 1490, 2481,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  56,   51,   29,  351,  128,    2, 1490,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  51,    5,   37,  117,    7,   15,    9,  409,    6, 1058]),\n",
       " array([  53,  439,  285,   50,    2, 3566,   22,  196,  141,    0]),\n",
       " array([  14,  155,    7,    5,   78,   80,    2, 1490, 1058,    0]),\n",
       " array([  25,   56,   25,    1,    1, 3430,    0,    0,    0,    0]),\n",
       " array([   4,    2, 2722, 2636,    2, 2628, 1363,    0,    0,    0]),\n",
       " array([ 10,   1,  20,   1, 196,  28, 120,   1,   0,   0]),\n",
       " array([  25,    7,    1,   40, 1281,   14,   10,    0,    0,    0]),\n",
       " array([ 60,  41,  13, 110,  25,   7,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 19,   1, 351,  29,   0,   0,   0,   0,   0,   0]),\n",
       " array([  2,   1, 210,   2,   1, 349,   0,   0,   0,   0]),\n",
       " array([   2, 3154,  133,    2,  596,   40,  733,    0,    0,    0]),\n",
       " array([  40, 2881,    2, 3036,    2,  266,   40,    1,    0,    0]),\n",
       " array([  15,  205,    1,    3, 2611, 2675,    0,    0,    0,    0]),\n",
       " array([11, 21, 40,  1, 39, 10, 60,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([29, 55,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1814,   16,   21,  383,  910,   29,   55,   29,   55,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  87,   33,    2,    1, 1490,   18,    1,    0,    0,    0]),\n",
       " array([ 103,   12,    2, 1631,   48,    2,  407,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([56, 29, 55,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1306,    1,   39,   60,   95, 2004,    0,    0,    0]),\n",
       " array([  29,  231,    2, 1490,  351,    0,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  31, 117,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([  39,  585, 3820,    9,    1,   29,    7,   24,  234,    0]),\n",
       " array([601, 850, 585, 125,   2,   1, 351,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3258,  244,  301,   17,    0,    0,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([887,  16,  21,  46, 328,   0,   0,   0,   0,   0]),\n",
       " array([  19,  120,  392, 1490,   59,    1,    0,    0,    0,    0]),\n",
       " array([  13, 1920,   84,   20,    1,    3,  141, 2481,    0,    0]),\n",
       " array([ 139,   12,   17,    8,    1,  208, 1017,   23,    0,    0]),\n",
       " array([  10,    5, 1218,    2,  580, 1978,   57,   89,    0,    0]),\n",
       " array([ 53,   7,  42, 189,  81,   3, 741,  17,  12,   0]),\n",
       " array([ 471,    5,   69,    2,    1,    3,    2, 2561,    0,    0]),\n",
       " array([   6,    2, 1329,  407,   22,   39,    7,   42,  532,    0]),\n",
       " array([  5, 415,  17, 473,   2, 531,   6,  19, 147,   0]),\n",
       " array([196,   4,   2, 675,   2, 133,   4,   2, 979,  48]),\n",
       " array([   3,  473,    2,    1,    3, 2343,    6,   94,    0,    0]),\n",
       " array([   2,    1,    1,    3,  882, 3604, 1736,    0,    0,    0]),\n",
       " array([  50,   16, 1218,   10, 1538,    1,    0,    0,    0,    0]),\n",
       " array([3891,   60,  189,    3,  171,   10,   34,   57,  240,    0]),\n",
       " array([   7,    8,   46,    1,  500,    2, 1490,  543,   16,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([137,  51,  56,  56,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([171,  34,  57, 240, 142,   0,   0,   0,   0,   0]),\n",
       " array([ 98,  29,   5,  42, 959, 112,   4, 524,   0,   0]),\n",
       " array([ 82,   5, 115,  80,   8,   1, 111,  10,  34,   0]),\n",
       " array([  50,   16,   42,  300, 1218,    2,    1,    6,   34,    0]),\n",
       " array([  3, 168,  16,  22,   2,   1,  29,  71,   7, 817]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  17,   59,   88,  351,   61, 3845,    7,   21,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1281,    6,  302,   41,   21,   46, 1490,    0,    0]),\n",
       " array([   3,    7,    2, 2628, 2636,   14,    1,    0,    0,    0]),\n",
       " array([  65, 2742,    3,   65, 1318, 3723,  389,    1,    0,    0]),\n",
       " array([2525,    2, 3279,   48,    2,  572,    7,   37,  281,    0]),\n",
       " array([  32, 2118, 1396,   53,    7, 1218,    0,    0,    0,    0]),\n",
       " array([ 22,  17,   1,  52, 194,  50,  66,   4,   7,   0]),\n",
       " array([  3,  32, 177,  50, 969,  29,  42,   7, 131,   0]),\n",
       " array([   7,    2,  169, 3320,    6,   21,    1,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,    2,  169, 3320,   90,    2,  169, 3320,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 14,  10, 145,  74,  48,   2,   1,   1,   1,   0]),\n",
       " array([   6,   21,  120,  790, 2115,   26, 3649,    1,    0,    0]),\n",
       " array([  26, 1921,   10,  129,  852,   11,  147,    4,  682,    0]),\n",
       " array([   1,   89,    4,  766,   99, 1331,    0,    0,    0,    0]),\n",
       " array([  22,   80,    7,  501,   19, 2879,    1,    3,    1,    0]),\n",
       " array([ 302,    3,   38, 3447,   41,   57,    2,  626,    6,  786]),\n",
       " array([  2,  74, 649,  86,  24,   1,   0,   0,   0,   0]),\n",
       " array([1454,  152,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([527, 327,   2, 390,   7,   1,   1,   0,   0,   0]),\n",
       " array([  10,    1,    2,  172,    1,    6,   19, 1440,    0,    0]),\n",
       " array([ 80, 969,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 36,  24, 195,  19,  46, 218,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   10,   31,  102,   46,  248,    4,   43,   31, 1124]),\n",
       " array([ 1,  1, 29, 58,  7, 24,  7,  1,  0,  0]),\n",
       " array([ 10,  84, 123, 212, 123, 373,   2,  74,   1,   7]),\n",
       " array([  2, 205, 308,   7, 450,  23,  10,   1,   4,   7]),\n",
       " array([  97,   23,   87,  281,    7, 3027, 1697,    7,    1,    0]),\n",
       " array([97,  1,  1,  7, 41, 32,  1, 32,  0,  0]),\n",
       " array([  64,   12,    2,    1,    6,  477,   81,    2, 2669,    0]),\n",
       " array([ 52,   1,  11,   2, 374,  19, 638,  12,   0,   0]),\n",
       " array([  4,  80,  27, 446, 202, 886,   1,  27,   0,   0]),\n",
       " array([  3, 699,  10, 466,  95,  17,   0,   0,   0,   0]),\n",
       " array([ 103, 1472, 2174,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([1472,   19,  391,    3,   19, 1722,   41,    0,    0,    0]),\n",
       " array([   9, 1013,  775, 2031,  103, 1703,  120,   10,    0,    0]),\n",
       " array([  53,   58, 1962,   20, 1175,   23,   10,    1,    0,    0]),\n",
       " array([  81,   19, 2414,    1,   15,    1,    6,  951,    0,    0]),\n",
       " array([   3,    1,  174,    1,   15, 2922,  829,  563,  599,  563]),\n",
       " array([  15,  282, 2358,    7,   42,  661,    9,  319,    0,    0]),\n",
       " array([  3, 185,  27, 152,  10,  59,  44,  19, 391,   0]),\n",
       " array([  27, 1138,   10,   59,   19, 2176,  327,    2,  390,    0]),\n",
       " array([  10,   11,  104, 1423, 2124,    6,    2,  445,    0,    0]),\n",
       " array([   7,  535,  170,    2,  152, 1520,  103,    0,    0,    0]),\n",
       " array([480,   2, 260, 273,   7,  11,   1,  53, 252,   0]),\n",
       " array([  58, 1817,   47,   74,  356,  327,   65, 2568,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  14, 1390,   57,   65,  161,    1, 1203,   60,   71,    0]),\n",
       " array([  2, 445,  12,  56,   1,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([829, 847,  60,  71,   0,   0,   0,   0,   0,   0]),\n",
       " array([1745,  458,   33,    2,  477,    3, 2604,    4,   93,    0]),\n",
       " array([ 327,  163,    5,    2, 1319, 1202,   84,    4,  981,    0]),\n",
       " array([103,   1,   3, 103,   1, 649,   1,   0,   0,   0]),\n",
       " array([  3, 102, 112,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,    1, 1069, 2617,  751,    0,    0,    0,    0,    0]),\n",
       " array([   3,    1,  110,   25,  190,   13,   11,   65, 2372,    0]),\n",
       " array([1717,   65,    1, 2562,   60,   71,  413,    0,    0,    0]),\n",
       " array([2402,  394,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  58,    2, 2347,  362,  934,   65,    1,    0,    0,    0]),\n",
       " array([  3,  72,  16, 364,   8, 465,  67,  80,   9,   1]),\n",
       " array([  15, 2853,    6,  104,    1, 1760,   25,  467,    0,    0]),\n",
       " array([  25,    5,  231,    1,    8, 3580,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181, 104,  41, 788,   1,   1,   0,   0,   0,   0]),\n",
       " array([  14,  171,    1,   60, 1071,    1,    0,    0,    0,    0]),\n",
       " array([  82,   41,   60, 1362, 2739,   22,    5,  369,    7,    0]),\n",
       " array([  29,  500,    2,  205, 2520,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 60,  41,   1, 829, 847,   0,   0,   0,   0,   0]),\n",
       " array([  60,  279,   60,   76,    1, 3388,  284,    1,    0,    0]),\n",
       " array([  10,    1,  963, 1146, 1098,   10, 1827,   86, 1126,    0]),\n",
       " array([  10, 1160,   59,  128,   14, 1945,   10,    2,  260,  530]),\n",
       " array([1390,   14,    2,  683,  153,  337,   15,  104,    1,    0]),\n",
       " array([  60,    1,   65,    1,   53,  145, 2481,    0,    0,    0]),\n",
       " array([   3,    9, 2612, 1687,   66,    9,  517,   74,    0,    0]),\n",
       " array([  4, 488,   2, 133,   6,   1,   0,   0,   0,   0]),\n",
       " array([   3,   80,  719,  264,  155,    1, 2852,   65, 2450,    0]),\n",
       " array([ 25,  60,  58, 829,  66,  47,   2,   1,  48,   2]),\n",
       " array([ 1, 65,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,   12, 1687,   66,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 831,  692,    4,  927,   65, 3913,    1,    0,    0,    0]),\n",
       " array([   6,   65,  161, 1247, 1221,    1,  293,    0,    0,    0]),\n",
       " array([232,   1,   3,   5,  93,   1,   0,   0,   0,   0]),\n",
       " array([  2,   1,  87,  24,  89,   1,   2, 445,   0,   0]),\n",
       " array([ 251,   28, 2330,   15,   16,   17,   31,   11,  118,    0]),\n",
       " array([766,  81, 264,   3, 769, 284, 865,   1,   0,   0]),\n",
       " array([14,  1,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 21,  12, 517,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 75, 410,   7, 287,   7,   1,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 972, 1187,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 62, 327,   2, 390,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  229,   12,   51,    2, 1099,   41,   11,  395,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  69, 991,  47, 818,  55,  36,  37, 590, 433]),\n",
       " array([  40, 3530,    1,   98,   40,  262,    1,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 225,   96,  139,   10,    7,   24, 2378,  448,   79,    0]),\n",
       " array([   2, 1099,   41,   11,  395,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([60, 24,  9,  1,  0,  0,  0,  0,  0,  0]),\n",
       " array([2067,  342,   10,   31,  239,    7,    4,  818,    0,    0]),\n",
       " array([   5,  565,   11,    1,   20, 2347,    0,    0,    0,    0]),\n",
       " array([  3,  76,   5, 144, 238,  22,  29,   5,  69,   0]),\n",
       " array([  5,  58, 456,  16, 337,  23,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   7,   24, 1030,  463,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 76, 630,   4, 630,   2, 187,  33,   2, 511,   3]),\n",
       " array([  81,    8, 1155, 1229, 2306,    4,   80,    0,    0,    0]),\n",
       " array([ 337,    8,  664,   15,   27,   23,   12,    9, 1792,    0]),\n",
       " array([  10,    5,   69,  450,    4, 2160,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 55, 446, 225,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([765,  81, 323,   4, 104, 664,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  17,   12,   19, 1306,  839,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([51, 17, 12,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   3,    5,   69, 2001, 1505,  778,   26,    0,    0,    0]),\n",
       " array([ 361,   98,   16,  240,   54,  537,   57, 2067,  246,    0]),\n",
       " array([  29,  129,   26, 2879, 4041,  112,    0,    0,    0,    0]),\n",
       " array([1505,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  32, 1187,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  67, 2376,   81,   74,    1,    3,  421,   15,    1,    0]),\n",
       " array([251, 188, 932,  21, 388,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([48,  1,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  19,  634,    4,    2, 1319,   97,    5,   93,    0,    0]),\n",
       " array([  40, 1807,  208,  765,   79,    0,    0,    0,    0,    0]),\n",
       " array([1505,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([152, 225,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181,  72,  66, 427,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1099,   24,  132, 1390,  105,  104, 3447,  770,    0]),\n",
       " array([   4,    1,   65,    1, 3262,    1,    0,    0,    0,    0]),\n",
       " array([  19, 1139, 1653,   56,  284,  160,  427,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 59, 195,  94,  28, 450,  25,  12,  21, 225,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,  320,   32, 1822,    0,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  73,   36,   76, 2759,  692,   14,    2,  307,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([2143,    7,   20, 1446,    3,  186,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 181,   22,   20, 2860,    0,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 145, 1022,   23,   31,   13, 1344,    4,    1,    2,  260]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,    2, 2354,  841,    0,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  432,  664,    1,   27,   23,   12, 1168,    0,    0]),\n",
       " array([100, 450,   4,  18,  28, 794,   0,   0,   0,   0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([110,   9, 408,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,   15,   46, 1417,    1,    2, 1422,    0,    0,    0]),\n",
       " array([  53,   23,    1,   47,   57, 3516,   22,    5,   42,  789]),\n",
       " array([  20, 3601,  115, 2009,    4,   18, 1482,    0,    0,    0]),\n",
       " array([480, 323,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1569,   57,    2,   53,   23, 3244,    0,    0,    0,    0]),\n",
       " array([  11,  241,  702,  339,   56, 2403,  115,   13,    0,    0]),\n",
       " array([216,  18, 828, 123,  54,   1,  64,  33,   0,   0]),\n",
       " array([   9,  318, 1717,    2,   89,   14,   29,    1,    0,    0]),\n",
       " array([  37,   18,    2,    1,  591,  171,   23, 1533,    0,    0]),\n",
       " array([   4,    2, 2837,    6,    9,   94,    3, 2406, 2447,    0]),\n",
       " array([ 31,  55, 535, 112,   6, 225,  48,  39,  23,   0]),\n",
       " array([  92, 1395,    2,  388,    0,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([872,  39, 389,  75,  56,   0,   0,   0,   0,   0]),\n",
       " array([1440,   10,   28,    1,   47,  225,   37,    0,    0,    0]),\n",
       " array([   6,   20,    1, 2928,  323,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([49,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([630,  34, 323, 805,  41,   4, 225,   0,   0,   0]),\n",
       " array([171, 225,   1,  66,  13,   3,  34,  20, 742,   0]),\n",
       " array([  4, 225,  37,  18, 805, 171, 310,   0,   0,   0]),\n",
       " array([  11, 1401,   23, 1949,   13,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([291, 224,   3, 125,   0,   0,   0,   0,   0,   0]),\n",
       " array([  61,    2, 1034,   12,  128,    3,   11,   29, 2415,    0]),\n",
       " array([ 54,  64,  20,   1,  23, 714,   0,   0,   0,   0]),\n",
       " array([ 81,  21, 432, 936,   0,   0,   0,   0,   0,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([291, 703,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  28,   19, 1440,   12,  342,    0,    0,    0,    0,    0]),\n",
       " array([  10,   60,    6,  302,   41,    1,   11,   40, 2742,    0]),\n",
       " array([  3,  93,  61,  36, 982,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 12,  17,  13, 429,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 29, 195,  24, 151, 314,  47,  11,  21, 329,   0]),\n",
       " array([ 10, 231,  18, 536,   4,   1, 968, 251, 302,   0]),\n",
       " array([ 92,   1,  96,  13, 956, 418, 220,   0,   0,   0]),\n",
       " array([228,   5, 311, 730, 104,  41,   2, 248,   5, 131]),\n",
       " array([  5,  24,   2, 985,  62, 609,  62,  17,  12,   0]),\n",
       " array([  60,   24, 2605,    9,  264,   22,   17,   12,   13,  604]),\n",
       " array([ 815,   14, 1699,   52, 2499,    2, 3136,   12,  169,    0]),\n",
       " array([   2,  307, 2628,    3,   17,   12,    1,    0,    0,    0]),\n",
       " array([323, 225,  19, 180, 592,   0,   0,   0,   0,   0]),\n",
       " array([ 103,   12,    6,  302,  637, 2168,   64,    6,    7,    0]),\n",
       " array([   3, 1505,  778,    9,  120,  794,  820,    0,    0,    0]),\n",
       " array([104, 403, 951,  47,  21,   1,   0,   0,   0,   0]),\n",
       " array([ 878,   96, 2779,  120, 2150,   96,   14,    7,    0,    0]),\n",
       " array([1834,    6,   17,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 40,   1,  11,   2, 657,   0,   0,   0,   0,   0]),\n",
       " array([ 36, 134,  82, 128, 469,  22, 302,  59, 501,   0]),\n",
       " array([  4, 351,  79,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 123,   95,    7,  131,   17, 1696,    0,    0,    0,    0]),\n",
       " array([  4, 273,  19, 169,   1,   1, 184,  73,   0,   0]),\n",
       " array([ 60, 888,  86, 315, 680,  53,   0,   0,   0,   0]),\n",
       " array([11,  2,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  17, 2108,    1,    4,  302,   33,    2,    1,    0,    0]),\n",
       " array([  36,   37,   18,    1,   11,   40, 2799,   53,   59,    0]),\n",
       " array([   4,  105,   11,  193, 2524,  251,  788,  302,    0,    0]),\n",
       " array([  87,   93,   36,   76, 3858,    0,    0,    0,    0,    0]),\n",
       " array([165, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([152, 342,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 105,   19, 1836, 1304,    7,    4,   19, 2473,    0,    0]),\n",
       " array([  72,   79,  525,    4, 1232, 1185,    0,    0,    0,    0]),\n",
       " array([  39,   60,  243,  174,  138, 1424,   14,    2, 1916,    0]),\n",
       " array([ 272,   19, 1095,   22,    5,  131,  585,  281,    0,    0]),\n",
       " array([   1,   13, 1358,   14,   79,    0,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 469,  13,  10,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 106,  50,   1, 181,  54,   0,   0,   0,   0]),\n",
       " array([ 99,   1,   6,  65, 264,  41, 284, 702,   0,   0]),\n",
       " array([  3, 337,   1,   5, 168,  19, 805,   0,   0,   0]),\n",
       " array([  39,   36,    3, 1187,  225,  869,    4,  358,    0,    0]),\n",
       " array([ 96, 694, 700,  79,  36,  37, 195, 537,   0,   0]),\n",
       " array([184,  74, 115,  42,  32,  54,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   2,  260, 2028,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   3,  273,   19,  805, 1110,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([165, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,  160,    7,  236, 1278,   52, 1820,  428,   11,    9]),\n",
       " array([  54, 3763, 1057,   39,    8,  122,   76,    8,  326,    5]),\n",
       " array([  87,    1, 2312,   11,   10, 1324,  767,   23,    0,    0]),\n",
       " array([904, 173,  64,  11,   2,   1,   6,  20, 401,  97]),\n",
       " array([ 23,  58, 315, 120,  77,  73,  82,  23,  59,  22]),\n",
       " array([  1,   3,   2, 337, 122,   6,   8, 971,  73,   0]),\n",
       " array([ 647,   15,    1,    1,   34, 2175,   20,  177,   73,    0]),\n",
       " array([  14,    9,  159,    6,  377, 2707,    9,  223,   87,   13]),\n",
       " array([1903,   27,   88,  380,   50,   38, 2018,    5,    1,    0]),\n",
       " array([ 61, 173,  58, 662, 110,   9, 557,  10,  17,  59]),\n",
       " array([  32,  216,   64,    1,    4,  829,   33,    2, 1264,   39]),\n",
       " array([   1,  128,   17,   13,  881,   59, 1293,    4,   72,   27]),\n",
       " array([ 997,   97,   23,   59,   84,    4,  281, 1569,    4,    9]),\n",
       " array([ 373,    5,  530,   27,   50,  791,   23, 3419,   20, 1320]),\n",
       " array([ 619,   15, 2131,    5,  117,   43,  236,    5,    1,   13]),\n",
       " array([ 54,  11, 367,  57,  89, 845,  23,  59,   9,   1]),\n",
       " array([  64,   44,   11,   89, 1351,   23,   92, 2597,  245,    9]),\n",
       " array([94,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  22,   92,   23, 1035,   11,    2,  388,  259,   61,   55]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 55,  20,  46, 556,  87,  24, 151,   8, 122,   5]),\n",
       " array([1104,   58,   24,  559,  713,  125,   16, 2325,    0,    0]),\n",
       " array([   1,   92,    5,    9, 2421,  600,  524,   11,    8,   77]),\n",
       " array([1721,    3,  255,  376,  267,   64,  249,    3,    8,   46]),\n",
       " array([ 225,    5,   92,  344,   92, 2191,  200, 1784,   14,   65]),\n",
       " array([ 659,   64,   74,    1, 3345,  112,    6,  936,    0,    0]),\n",
       " array([1373,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 259,    2,  121, 1140,   12,   49,    4,  938,    7,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 369,    7,  102,   16,  168,    4, 1915,  166,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310,   7,  37,  13,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 653,    5,  125,  338,   19, 1369, 1469,    0,    0,    0]),\n",
       " array([  98,   27,  709,  342,  174,   33,    2, 1231,    0,    0]),\n",
       " array([  25,  486,   50,    9,  203,    2, 1099,    1,   27,    0]),\n",
       " array([ 653,    5,   98,   27, 2544,  141,    3,  185,  141,    0]),\n",
       " array([ 49,  47,   7,   1,   7,  76, 807,  11, 179,   0]),\n",
       " array([ 171,    7,   76,  561,   11,  302,   20,  442, 1321,    0]),\n",
       " array([ 15,  20,   1, 158,  55,   1, 284,  23, 714,   0]),\n",
       " array([ 84,   4,   9,   1, 304,   1,   4,   1,   0,   0]),\n",
       " array([  52,   34,   52,  569,   20, 2392,    0,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  20,  442, 1321,   48, 3047,   32,  147,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 146,    7,  582,   17,   54, 1042,    9,   94,    0,    0]),\n",
       " array([  64,    1,   20,    1,    2, 3201,    6,    1,    0,    0]),\n",
       " array([ 73,  63,  95,   1,   1, 776,  13,   1,   0,   0]),\n",
       " array([  64,    1, 3088,   73,   17, 1892,  284,  147,    0,    0]),\n",
       " array([  57,    1,  465,    1,  117, 1140,    0,    0,    0,    0]),\n",
       " array([ 36,  41, 741,   4, 286,  38, 290,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 570, 1041,    8,   45,   50, 1170,  342,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 420,  636,  342,  210, 1717,   20,  922,    0,    0,    0]),\n",
       " array([   3, 1335,   81,   20,  947,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  8, 891, 140,  46, 159,   4,   7,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([164, 259,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,   69,  991,    4,   98,   19, 3581,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  61,   42,    7,  140,    7,   41, 3013,    1,    0,    0]),\n",
       " array([ 29,  41,   7,   1,  62,   9, 957,   1,  11,  46]),\n",
       " array([393,  61, 435,  19, 234, 122,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,  385,   19, 3581,   56,   46,  259,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   92,  344,   98,    2, 1105,    3,  125,    9, 1469]),\n",
       " array([ 155,   81,   20, 2916,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 48,   8, 218,   2, 340, 122,  67,   1,   9,   0]),\n",
       " array([ 157,  798,  298,   48,    8, 1270,    5, 2369,   81,   27]),\n",
       " array([2501,  630,   88,  380,  463,  320,  110,    9,    0,    0]),\n",
       " array([   1, 1389,    5,  419,   27,  682,  316,    9,    1,    0]),\n",
       " array([   1,    3,   73,   23, 2007,   17,   23,   72,   17,   75]),\n",
       " array([156,   3, 316,  17, 156,   3, 724,   3, 724,  23]),\n",
       " array([194,   3, 156,   1,  17, 156,  52, 815,  20,   0]),\n",
       " array([406,   1,  27,  52,  61, 491,  23,  95,  28, 243]),\n",
       " array([1339,    3,  880,   17,   48,    5,  516,   17,   61,   23]),\n",
       " array([17,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  74,   47, 1424,  340,    1,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([310,   1,  96,   9, 152, 363,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  9,   1, 259,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 49, 362, 934,  19,   1,   5,  86,  24,   7, 461]),\n",
       " array([   2, 1119,    1,   15,   16,   21, 1856,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,   46,  259,    5,   31,   13,  112,    6, 3711,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  13,  112,    6, 3711,    0,    0,    0,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([63, 37, 63, 37,  0,  0,  0,  0,  0,  0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310,  32,  33,  19, 601,  67,  13, 724,   2,   0]),\n",
       " array([3980,  184,    8,   45,  541,   50,    2,  664,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([583,   7,   1, 428, 120,   1,  49,   0,   0,   0]),\n",
       " array([  7,  86,  75, 938,   2,  46, 121,  10, 366,  11]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,   31,  456,   38, 2886,  681,    3,  938,   38,   15]),\n",
       " array([  8, 757,  22,   5, 142,  75, 770,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 90,   5, 160,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  96,   13,    4,  404, 1072,  123,   10,    5,  768,   77]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  7,  58,  18, 356,   1,  82,  60,  71,  34,   0]),\n",
       " array([   2,    1,   63,    1,   11, 3954, 1324,   95,   22, 1308]),\n",
       " array([  1, 312,   6,   1,  49,   5,  58,  19,   1,   0]),\n",
       " array([  76, 2907,   25,   19, 1462,   10,    7,  258,  168,    0]),\n",
       " array([  1,  17,  14, 405,  49,   7,  37,  75,  15,  79]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 32,  46, 259, 265,  16, 310,   5,  31,  13, 284]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 11, 396,   1,  75,  15,  16,   3,  67, 117,   7]),\n",
       " array([1571,  229,    6,   19,  326,    0,    0,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  46, 259,  85, 115,  18, 255,  82,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([2064,    5,   42,   13,  727,   15,    7,   85,  285,  229]),\n",
       " array([ 27, 347, 204,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310, 259,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  11, 2193, 1118,  139,    5,  311,    9,  567,  106,   17]),\n",
       " array([ 141,   17,   12,    2, 1099,   24,   88, 1095,  284,  170]),\n",
       " array([241, 323,   2, 580,  12, 220,  15,  74, 268,   6]),\n",
       " array([  40,  820,  264,   19,   45,    3, 1505,  778,   41,  243]),\n",
       " array([ 174,  138,   65,  445, 1185,   60,  198,  469,    0,    0]),\n",
       " array([  1,   3,   4,  80,  17, 811, 664,  21,  12, 139]),\n",
       " array([ 47, 109, 173,   3,  28,   5, 160,  75,  15,  79]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 102,   16, 1174,   46,  259,    5,   31, 1065,    7,   11]),\n",
       " array([ 238, 1452,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,  38, 525, 121,  25,  63,  12,  44,  63,  31]),\n",
       " array([2423,   40,  216, 2357,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  11, 1270,    5,  131,   63,   58, 1085,    7,   56,   55]),\n",
       " array([ 49,  46, 164, 121, 588, 837, 412,  30,   0,   0]),\n",
       " array([   1,  112,   48, 1240,    3,   75,  703,   15,   79,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 32,  57,   9, 218, 259, 310,   5,  86,  13,   5]),\n",
       " array([   7,  132, 2357,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 56,  55, 269,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1325,  194,  229,    9, 2060,   60,   24,  670,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  8, 476,   4, 429,  32,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 96, 163,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3245,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 71, 320,  40, 580, 670,   2, 592,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  60,  354,   11, 1266,   22,   24,   13,  707,   25,   82]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 28,   2,  46, 476,  12, 109,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 67, 784,  27,   6,   7,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,   67,  123, 1903,  123,  102,   27, 1164,    7,   27]),\n",
       " array([  14,  630,    9,  954,  379, 3351,    2,  907,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 61, 348, 219, 354, 104,   1,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 332,   21, 1786,    3,  630,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  55,   37,   36,  125,   65,    1,    3,   60, 1063,    0]),\n",
       " array([  44, 2365,    5,  588,   80,   79, 1112,   11,  648,    0]),\n",
       " array([  10,   36,   15, 4064, 1105,   78,  774,   50,  224,    0]),\n",
       " array([  4, 309,  40,   1, 208,  49, 966,  30,   1,   0]),\n",
       " array([   1,  342,   12,   23,  332,   19, 1098,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,  123,    9,   94,   10, 1818,    7,  376,   64,   23]),\n",
       " array([ 304, 1956,   64,    9,  234,    0,    0,    0,    0,    0]),\n",
       " array([ 645,   40, 1577,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  41,    1,  284,   40,  647,   56,  488,   40, 1098,    0]),\n",
       " array([ 344,   64,   60,   37, 1927,   79,  111,   40,  672,    0]),\n",
       " array([  53,   82,  540, 1517,   36,   24,   22,    1,   15, 2922]),\n",
       " array([1745,  627,    6,  680,    0,    0,    0,    0,    0,    0]),\n",
       " array([645,   7, 348, 219,   0,   0,   0,   0,   0,   0]),\n",
       " array([  85,   12,  342, 1366,   29,  648,   23,  308,    0,    0]),\n",
       " array([1854,   19,    1, 1095,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([48, 60, 41, 57, 17,  0,  0,  0,  0,  0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  65,  946,   18,   40, 2158,    1,  687,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 60, 179,  79,  13,  22, 713, 284,  65, 445,   0]),\n",
       " array([ 44, 239,  19,   1, 138,  19, 454,   3, 421,   0]),\n",
       " array([  15,  454,   54, 1357,   64,    1, 2229,    0,    0,    0]),\n",
       " array([ 646, 1505,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  60,   42, 2424,   79,  132, 1488,   40,  526,    0,    0]),\n",
       " array([  53,  308,   16, 2267,   15, 1406,   49,   47,    8, 1084]),\n",
       " array([  23,   10,    1,   67,  105,   27,   14,    9, 1611,    0]),\n",
       " array([   3,   23,   37,  808,  109, 2192,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  34,    2,    1,    6,    2, 2282,  399,   47,    7,    0]),\n",
       " array([   7,    1,    6,  302,    7, 2674,    1,    3,    1,    0]),\n",
       " array([   1,    7,  613,   10,    7,   78,   18, 3255,    0,    0]),\n",
       " array([ 673,   64,  483,    3,   74, 2668,  356,    0,    0,    0]),\n",
       " array([ 170,    2,  704,    9, 1786,    7,  553,    6,    1,    0]),\n",
       " array([  10,  203,    2, 2296,    6,  153,   61,   24,    7,  682]),\n",
       " array([  50, 1760,   10,    1,   58,  636,    1,    3,  420,    0]),\n",
       " array([  34, 1450,  932, 2476, 1429,    3, 1570,  668,    0,    0]),\n",
       " array([  15, 1461,    3,    1,  179, 1672,    3,  552,  287,    0]),\n",
       " array([  52,   33,    2, 1981,    6,  182,   67,  168,    2,  740]),\n",
       " array([  3,  80,   8, 664,  47,   7, 155, 817,  49,  47]),\n",
       " array([  39,  585,  190,  674,   56,  636,   66,    4,   65, 1327]),\n",
       " array([  25,   60,   79,    4,   40, 3963,    1,    0,    0,    0]),\n",
       " array([  28,   44,    2,  672,   41, 2130,   44,  345,   46,    1]),\n",
       " array([  96,   14,    2, 1377,  382,    1,   66,    0,    0,    0]),\n",
       " array([ 13,  14,   2,   1, 543,  16,   3,  42,   2,  84]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 1, 13,  5,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([165, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([123,   5,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  98,   60,   24, 1517,   27,   11,    0,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   4,    2, 3475,    5,  516,   27,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 29,  12, 662,   6, 225,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([529,  51,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3089,    2,    1,   57,    2,  157, 2396,    0,    0,    0]),\n",
       " array([ 15,  66,  23,   1, 103,  81,   2, 909,   0,   0]),\n",
       " array([  1,   4,  65, 672,  23,  12, 245, 525,   0,   0]),\n",
       " array([  4, 351,  34,   2, 445,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 152, 383,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 103,    1,    1,   20, 2566,  465,    0,    0,    0,    0]),\n",
       " array([   3,   73,   17, 3800,  528,  111,   26,  129,  440,  225]),\n",
       " array([   9,    1,    1,   25, 1595,   25,   26,  129,    0,    0]),\n",
       " array([  76,   13,   28,  683,    9, 2156,   26,  748,    9,  733]),\n",
       " array([ 196,    4,    1,  456,   13, 2411,    3, 3333,    0,    0]),\n",
       " array([ 337,   11, 2093,   22,   15,   30, 3076,  434,    3,    0]),\n",
       " array([   2,    1,    1,    6,   30, 2548,    0,    0,    0,    0]),\n",
       " array([ 26,   1, 249, 658, 978,  25,  39,   2, 187,   0]),\n",
       " array([  76,    1,    3,   95, 1618,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([155,  51,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  1, 225,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 291,  729,   27,  219,   52,   80, 1016, 1721,    0,    0]),\n",
       " array([ 89, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  21,   31,    5, 1132,    4,  302,    0,    0,    0,    0]),\n",
       " array([165, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 3,  5, 21,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([355, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   9,    1,  885,    5,  678,   21,   14, 1280,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  98,   62,  104,    1,   10,   42, 1430,   65,  534,    0]),\n",
       " array([  57,    9, 3151,    1,    1, 3039,    1,    0,    0,    0]),\n",
       " array([ 1,  6,  9,  1,  1, 10,  1, 58,  0,  0]),\n",
       " array([1837,   15,  215,   10, 2236,   66,  104,  873, 1760,    0]),\n",
       " array([ 251,   82,    2,  421,   18,  163, 1936,  111,  174,   15]),\n",
       " array([  3, 645,  29, 946,   2, 580, 308,   4,  27,   0]),\n",
       " array([ 85,  12,   2,  94,   6,   8, 553, 391, 342,   0]),\n",
       " array([2336,   40, 1911,   55,  794, 1505,  105,    0,    0,    0]),\n",
       " array([   1, 2980,    4,   80,   46,    2,  445,    0,    0,    0]),\n",
       " array([705,   5,  15, 215,  10,  24,   2, 539,  31, 507]),\n",
       " array([  4, 309, 323,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([446,  51,  26,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([  30, 2184,   70,  151,  100, 1413,   14,    0,    0,    0]),\n",
       " array([  9, 165, 690,   6, 421,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  51, 1531,   16,   13,    0,    0,    0,    0,    0,    0]),\n",
       " array([   8,  648,   70,   82,   13, 3907,   16, 1085,    7,   56]),\n",
       " array([   2,  147,    5, 1239,   12,  344,    1,    0,    0,    0]),\n",
       " array([ 64, 744,   4,  16,   4, 342, 141,   0,   0,   0]),\n",
       " array([  5,  31, 787,   3, 421,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  44,    2,  149, 3651,  382,    0,    0,    0,    0,    0]),\n",
       " array([406, 594,  11,  77,  15,  43,   3,  38, 169,   1]),\n",
       " array([   1,   30,    1, 1105,  719,  235,    0,    0,    0,    0]),\n",
       " array([2598,   18,   30, 1021,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 30, 328,  32, 376,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 64, 215,  63,   1,   1,  28, 269,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  26, 3874,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  75,  457,   30, 2069,   11,    2, 1788,    0,    0,    0]),\n",
       " array([ 185,  770,   34,    2, 2344,   48,    2,  907,    0,    0]),\n",
       " array([ 97,  60,  37,  93,  40, 319, 146,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 870,    7,    8,  208,   56, 1030,    0,    0,    0,    0]),\n",
       " array([ 36,  41,  49, 219,   0,   0,   0,   0,   0,   0]),\n",
       " array([  84, 1911,  642, 1122,   11,   40,  528,    0,    0,    0]),\n",
       " array([ 123, 2739,   11, 1915,  424,   16, 1630,    0,    0,    0]),\n",
       " array([  36,   37,   18, 1712,  156, 1049,   36,   24, 1053,    0]),\n",
       " array([ 33,   1,   3,   1,   1,  36,  24, 311,   0,   0]),\n",
       " array([   2, 2763,    6,   40,  208,  563,  820,  260,    0,    0]),\n",
       " array([951,  65,   1,  25,  36, 456,  40, 161,   0,   0]),\n",
       " array([  10,  140,   40, 1656,   15, 3379,    0,    0,    0,    0]),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([  78,  102,    7, 2856,    1,    0,    0,    0,    0,    0]),\n",
       " array([ 30, 229,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  595,    6, 1185,   24, 3598,    0,    0,    0,    0]),\n",
       " array([  3, 671,   4, 778,   3,   4, 225, 786,   0,   0]),\n",
       " array([   5,  419,   40, 1155,    4,   65, 3963,    1,    0,    0]),\n",
       " array([  3,  55,   5, 285, 146,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 171,   26, 2100,  396,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 653,   26, 2100,   13,   56,    0,    0,    0,    0,    0]),\n",
       " array([ 61, 244, 644, 228,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([814,  88, 380,   8,  45,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  96,   13,    9, 1786,    1,   36,  311,   65, 1577,    0]),\n",
       " array([  61, 2432,   26,   11,    9, 1786, 2436,   88,  380,    0]),\n",
       " array([  3, 272,  30, 229,  28, 521,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([4048,    6,    2, 1099,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 828,   16,   11, 2006,   10,    5,   59, 1695,    4, 3893]),\n",
       " array([ 403,   52,  956, 3552,  301,  252,   92,    5,   51,    0]),\n",
       " array([630,  88, 380, 228, 536,   8, 556,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1202, 1325,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 10, 435, 787,  25,  23,  76,   1,  48, 260,   0]),\n",
       " array([  23,  320,    2, 2544,    6,  225,    3,    5,   24,    0]),\n",
       " array([  1, 483,  27, 141,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  459,  546,   13, 1506,   50,    9,    1,    0,    0]),\n",
       " array([ 54,  64,   5,  93,   2, 457,   6, 225, 266,   0]),\n",
       " array([  50,  282, 3008,   94,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 49,   5, 100, 521,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([137,  39,   7,  49,  13,  11,   2, 147,   6, 800]),\n",
       " array([ 22,   1,  11,  19, 161,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  72,  16,   1, 563,   0,   0,   0,   0,   0]),\n",
       " array([  11,  395,   25,  457,   25,   73,    5, 1045,   11,  133]),\n",
       " array([  25,  685,   25,   73,   40, 2624,  159,   59,  163,    0]),\n",
       " array([3, 1, 1, 4, 1, 0, 0, 0, 0, 0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1234,    6, 2248,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  61,   12,   17,   15, 1505,  778,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 25,  15,   9,  94,   1, 301,   1,   0,   0,   0]),\n",
       " array([   1,   99,    4,  101,    3,   99,    4, 1465,    0,    0]),\n",
       " array([   1,   27,   52,    1, 2260,    2,  205,    0,    0,    0]),\n",
       " array([2391, 1185,   11,    2,  148,    6,  302,    0,    0,    0]),\n",
       " array([196,  84,   9,   1,   1,  11,   2,   1,   0,   0]),\n",
       " array([   4,   72,   27, 2104,   57,   31,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 97,  12,  10, 819,   0,   0,   0,   0,   0,   0]),\n",
       " array([  53,  448,   16,   60,   92,  636,    7,    4,   19, 3963]),\n",
       " array([ 97,  12,  23, 185,  27, 338,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,  27, 525,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   95, 1961,    2,  396,   22,   14,   40,  495,    0]),\n",
       " array([   2,  572,    1, 1294,  692,   14,   66,    0,    0,    0]),\n",
       " array([   2, 3533,  439, 4080,    2, 3783,   25,   60,   95, 3792]),\n",
       " array([  50, 3448,  637,   64,   60,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  22,   61, 2330,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 31,   2, 118, 624,   4, 117,   5,  42,  13, 131]),\n",
       " array([ 97,  12,   2, 592,  41,   7, 217,  48,   2, 657]),\n",
       " array([  39,   13,   90, 1590,    7,  184,    7,   41,   28,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,   24,   57,    1, 1030,    3,   95,    0,    0,    0]),\n",
       " array([1915,    4,  766,   40,  502,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 61, 366,  65, 786,  93,   7,  47,  53, 649,   0]),\n",
       " array([ 60,  24,   1,  65, 153,   6, 599,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  25,    5, 1026,  225,    0,    0,    0,    0,    0,    0]),\n",
       " array([  65, 2473,    5,    2,    1,   41,    2, 3849,    0,    0]),\n",
       " array([  6,  65, 262, 599, 613,  66, 342,   0,   0,   0]),\n",
       " array([ 65, 157, 133,   6, 275,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  42, 369,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([  33,   34,    2, 2472,  767,   36,   24, 1030,    0,    0]),\n",
       " array([  33,    2,  147,   36,   24,  913,  463,   33,    2, 1733]),\n",
       " array([  36,   24,  128,    4, 1572,  208,   10,    7,    1,    0]),\n",
       " array([ 243,   16,  170,  342,    3,   20, 3849,    0,    0,    0]),\n",
       " array([   3,   10,    7,   13, 1582,    2,  432,   22,    0,    0]),\n",
       " array([   1,    2,  584,   15, 1105, 3251,    3,    1,    0,    0]),\n",
       " array([ 36, 345,  21, 157, 380,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([171,   5, 231, 456,   0,   0,   0,   0,   0,   0]),\n",
       " array([  7,  76,   1,   4,   9, 276,   1,   0,   0,   0]),\n",
       " array([  3,   1,   1,   4,   7,  82, 617,   5, 134,   0]),\n",
       " array([ 763,   19, 3228,  105,   19, 1247,    6,  215,    0,    0]),\n",
       " array([  10,  262,  115, 1197,   19,  936,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([215,  41,  60,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  10,  120,   41, 2047,   39,  144,  110,   18,   62,    0]),\n",
       " array([  25,   17,   76,  565,    4,    1,   77,   21, 3507,    0]),\n",
       " array([767,   7,  98,  16,   1,  39, 144, 179,   0,   0]),\n",
       " array([1956,   20,  557,   64,   88,   67,  556,    0,    0,    0]),\n",
       " array([ 39, 144, 131, 646, 101,   1, 720, 126,   0,   0]),\n",
       " array([   3,   10,   20,  998, 2734,   64,  245,    0,    0,    0]),\n",
       " array([  72,   27,  525,   52,   28,  193,   28, 3549,    0,    0]),\n",
       " array([3281,  141,    4, 1820,   20, 1579,    0,    0,    0,    0]),\n",
       " array([  3, 427, 225,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  16, 525,  80,   7,   9, 465,   6,  16,   0]),\n",
       " array([  39,  104,  883,   18,   13, 1535,   53,    6,    7,    0]),\n",
       " array([  22,   12,  956, 1099,  255,    6,    7,   22,   12,    0]),\n",
       " array([1725,    4,  203,  170,    2,  169,  342,    0,    0,    0]),\n",
       " array([   9, 2293,   25,  924,   25,   20,    9,  962, 1665,    0]),\n",
       " array([171, 527,   4,  34,  86,   5,   1,   0,   0,   0]),\n",
       " array([ 50,  34,   2, 257,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 37, 203,   2, 388,  11,  99, 205, 421,   0,   0]),\n",
       " array([  25,  296,   31,   18, 3510,  303,    7,    4,  774,    0]),\n",
       " array([  3, 956,  37, 857, 633, 112,   8, 607,   0,   0]),\n",
       " array([  53,  153,   41,  262, 2386,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 774,   47,    8, 1084,    0,    0,    0,    0,    0,    0]),\n",
       " array([80, 46, 21,  1,  3,  7, 37,  0,  0,  0]),\n",
       " array([3715,   11,   34,   15,   79,    0,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 28,  72,   2,   1,  18,   1, 273,  19,   1,   0]),\n",
       " array([ 25,   5,  24, 243,  66, 174,  39,   5,  42, 415]),\n",
       " array([ 215,    1,    4,   40, 1197,    2,  257,   31,  624,    0]),\n",
       " array([  14,    9,  912, 2391,   39,   36,  569,    2,  657,    0]),\n",
       " array([ 36, 142, 273,   2, 907,   0,   0,   0,   0,   0]),\n",
       " array([1955,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([179,  13,  40, 497,  51,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 224,    3, 1517,   19,  672, 3932,    0,    0,    0,    0]),\n",
       " array([  40,    1,   49,    4,    2,  820,    1, 1708,   79,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 67, 421,  15, 255,  22,  43,  14,   5,  42, 391]),\n",
       " array([637,  64,   9,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,  391, 1721,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  13,    1,    1,    9, 3395,    5,    1,    0,    0,    0]),\n",
       " array([  54,   64,   30, 1569,    3, 1311,    1,   30,  581,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,   2,  89,   1, 200,   2, 800, 819,   0,   0]),\n",
       " array([   3,    2,  260, 1089,   27,  316,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 39,   5, 508, 225,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,   16,   84,    9, 2397,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 332,  104,  403,  534, 2067,    0,    0,    0,    0,    0]),\n",
       " array([ 525,    5, 1030,   11,   19, 1185, 1098,    0,    0,    0]),\n",
       " array([   3,  128,   29,  648,    5, 1293,   96,   13,    8,  147]),\n",
       " array([ 767,   26, 1283,   16,    1,   14,   30,  625,    0,    0]),\n",
       " array([  1, 111,  30, 264,   4,   2,   1,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([747,  26,   2,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([  10,   59,    2, 1731,    6,   19,    1,    1,    0,    0]),\n",
       " array([  26, 1349,   13, 1906,   16,   62,    0,    0,    0,    0]),\n",
       " array([   1,    3,   13,  794,    7,   24, 3393,   16,    0,    0]),\n",
       " array([  11,   19, 2437,    1,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 39,   5,  87, 117,  43, 613,  21,  30, 418, 648]),\n",
       " array([  1,  13, 424,  30, 780,  22,  67, 556,  17,   0]),\n",
       " array([  97, 1281,   37,    1,  297,   15, 1628,    0,    0,    0]),\n",
       " array([  97,  169, 1780,   37,  765,    3,    1,    0,    0,    0]),\n",
       " array([   5,    2,  384,    1,   97,  891,   37,   18, 3664,    0]),\n",
       " array([   3, 2405,    1,  125,   54,   97,    2,    0,    0,    0]),\n",
       " array([1238,  692,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  10,   15,    2,    1, 2960,  391,  249,  805,    0,    0]),\n",
       " array([ 37,  71, 170,  65, 454,  36, 385,   2, 260,   0]),\n",
       " array([ 40, 302,  70, 110,   9, 733,   0,   0,   0,   0]),\n",
       " array([  82, 1591,   26,    4,    9,    1,    6,   21,  895,    0]),\n",
       " array([ 547, 2688, 3128,  138,    0,    0,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 580,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  62,   12,    2, 2881,   36,    2,    1,    0,    0,    0]),\n",
       " array([ 728,   26, 1491,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([160,  44,  32,  54,   8, 223,   0,   0,   0,   0]),\n",
       " array([103, 320,   9,   1,   4,   1,  38, 147,   0,   0]),\n",
       " array([  73,   63,  435, 1531,   16, 2680,   16,    5,   24,  163]),\n",
       " array([ 25,   7,  24, 163, 304,  29,   5, 115,   1,   0]),\n",
       " array([ 25,   7,  24, 151, 304,  14,   8, 659,   0,   0]),\n",
       " array([ 23,  10, 320,  22,   1,  20,  46,  31,   0,   0]),\n",
       " array([ 70,   1, 109, 968,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 7, 37, 13, 18,  0,  0,  0,  0,  0,  0]),\n",
       " array([  2, 392,   6,  19,   1, 302,  86,  93,   0,   0]),\n",
       " array([   2, 3292,    6,   38,  161,  574,    9,    1,    0,    0]),\n",
       " array([637,  64,   9,   1,  32, 376,  64,   9,   1,   0]),\n",
       " array([   4,  955,   19,    1,    3,    4, 1107,   10,    0,    0]),\n",
       " array([  53,    4,    2,    1,    3, 2072,    6, 2332,    1,    0]),\n",
       " array([  58,  540,   22, 2354,  167,    5,  369,    7,    0,    0]),\n",
       " array([  11, 1347,    6,   29,    7,   41,   13,    4, 1913,    0]),\n",
       " array([  29,    7,   24,    1,   40, 1095,  125,   16,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  24,  99, 721,  81,  16,   3,  60,   1,   0]),\n",
       " array([   4,  125,  680, 3436,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([87, 60, 13,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  56,  258,   60,    1, 1028,    1,    0,    0,    0,    0]),\n",
       " array([   3, 1011,  680,   15,  101,    6,   34,    2, 1553,    0]),\n",
       " array([1203,   36,   24,  908,   46,    3,   46, 2095,    6,   34]),\n",
       " array([   2, 1879,   11,   21,  657, 3867,    3,  445,    0,    0]),\n",
       " array([  36, 3434,    7,    2,    1,    4,   18,  908,  284,    0]),\n",
       " array([138,   2, 572,   1,  57,   0,   0,   0,   0,   0]),\n",
       " array([  19,  337, 1247,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 385,   7, 580,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 22, 142,  80,   8, 133, 781,   4, 105,   0,   0]),\n",
       " array([   9, 3794,    4,  858,    8,  465,    5,   42, 1919,   17]),\n",
       " array([  3, 190,  81,   8, 572, 268,  15, 215,   0,   0]),\n",
       " array([  10,   24, 1491,    2,  926,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  78,  104,  695, 1681,   53,    7, 2599,    0,    0,    0]),\n",
       " array([ 134,  457,   54,   73, 1577,    3, 1208,   37,    0,    0]),\n",
       " array([   5,    2,  657,  345, 3094,   72,    1,    3,    1,   18]),\n",
       " array([128,  34,   6,   1,   1,   0,   0,   0,   0,   0]),\n",
       " array([  73, 1055, 1560,  752,   25,    2,    1, 2896,    0,    0]),\n",
       " array([ 72,  27,  18, 128,   9,   1,  14,   2, 664,   0]),\n",
       " array([  32,   54,    5,   71,   14,   10,    5,   24,   13, 2055]),\n",
       " array([   8, 1297,   10,    1,   52,    1,   99,    1, 1044,    0]),\n",
       " array([ 53, 402, 887, 485, 193, 252,  24, 163,   0,   0]),\n",
       " array([   7, 4084,   16,  284,    0,    0,    0,    0,    0,    0]),\n",
       " array([11,  1,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 25,  39,   5, 712,   8, 234,  87,  18,   1,   0]),\n",
       " array([  11, 2332,    1,   15,  366,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 100, 2354,   41,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([  54, 1182,    4,   19,   46,  556,   64,    1,    0,    0]),\n",
       " array([  4,  79,  10, 102,   7, 879,  33,  19, 601,   0]),\n",
       " array([  39, 1028,  428,    7,   18, 3057,   56,  239,    7,    0]),\n",
       " array([  84,   74,   10,  433,   20, 1655,  806,   11,    1,    0]),\n",
       " array([  55,  518, 2575,   15,    7,  167,   18,   17,  604,    0]),\n",
       " array([  25,    4,   79,    4,   34,    2,  187,   10, 1187,  225]),\n",
       " array([2243,   21,  664, 2176,   11, 3319,    6,    2,   53,    0]),\n",
       " array([   8,  152, 2881,  604,    4,    2,    1,    5,  102,   27]),\n",
       " array([  15,   34,   20, 3962,    1,    3,   50,   21,  118,    0]),\n",
       " array([  14,   29,   23,   95,  138, 1185,  185,   27,    0,    0]),\n",
       " array([  15,   34,    2,    1,    3, 2440,    6,    2, 3620,    0]),\n",
       " array([1187,  225,  150,  203,    0,    0,    0,    0,    0,    0]),\n",
       " array([   2,    1, 1784,  195,    0,    0,    0,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1187,  225,  150,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([150,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  31,  75, 974,   0,   0,   0,   0,   0,   0]),\n",
       " array([   3,   73,    8,  246,   12,  149,    7,   37, 1295,    0]),\n",
       " array([ 815,    5, 1487,   52,   32,    1,    5,  385,    7,    0]),\n",
       " array([   5,  331,    4, 4030,   19, 2881,    3,   57,   34,  492]),\n",
       " array([ 4,  1, 19, 46,  1,  0,  0,  0,  0,  0]),\n",
       " array([  4,   2,   1,   6,   8, 264,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  28,    4,   40, 1011,    0,    0,    0,    0,    0,    0]),\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDzSOjNwCWNh"
   },
   "source": [
    "### Generate training examples from sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BehvYr-nEKyY"
   },
   "source": [
    "`sequences` is now a list of int encoded sentences. Just call the `generate_training_data` function defined earlier to generate training examples for the word2vec model. To recap, the function iterates over each word from each sequence to collect positive and negative context words. Length of target, contexts and labels should be the same, representing the total number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:19:37.821824Z",
     "iopub.status.busy": "2023-12-07T12:19:37.821571Z",
     "iopub.status.idle": "2023-12-07T12:20:20.086500Z",
     "shell.execute_reply": "2023-12-07T12:20:20.085764Z"
    },
    "id": "44DJ22M6nX5o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/32777 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 105/32777 [00:00<00:32, 1017.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  1%|          | 207/32777 [00:00<00:34, 932.24it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  1%|          | 301/32777 [00:00<00:34, 928.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  1%|          | 395/32777 [00:00<00:36, 897.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  1%|▏         | 485/32777 [00:00<00:38, 848.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  2%|▏         | 597/32777 [00:00<00:34, 919.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  2%|▏         | 690/32777 [00:00<00:36, 873.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  2%|▏         | 778/32777 [00:00<00:37, 849.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  3%|▎         | 869/32777 [00:00<00:36, 865.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  3%|▎         | 958/32777 [00:01<00:36, 870.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  3%|▎         | 1051/32777 [00:01<00:35, 887.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  4%|▎         | 1157/32777 [00:01<00:33, 930.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  4%|▍         | 1253/32777 [00:01<00:34, 921.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  4%|▍         | 1370/32777 [00:01<00:31, 993.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  4%|▍         | 1470/32777 [00:01<00:32, 948.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  5%|▍         | 1566/32777 [00:01<00:33, 938.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  5%|▌         | 1668/32777 [00:01<00:32, 958.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  5%|▌         | 1765/32777 [00:01<00:34, 891.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  6%|▌         | 1871/32777 [00:02<00:33, 935.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  6%|▌         | 1985/32777 [00:02<00:31, 989.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  6%|▋         | 2086/32777 [00:02<00:32, 953.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  7%|▋         | 2208/32777 [00:02<00:29, 1027.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  7%|▋         | 2312/32777 [00:02<00:30, 986.35it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  7%|▋         | 2429/32777 [00:02<00:29, 1029.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  8%|▊         | 2552/32777 [00:02<00:27, 1080.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  8%|▊         | 2662/32777 [00:02<00:27, 1085.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  8%|▊         | 2772/32777 [00:02<00:29, 1028.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  9%|▉         | 2876/32777 [00:03<00:29, 1014.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  9%|▉         | 2999/32777 [00:03<00:28, 1063.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  9%|▉         | 3106/32777 [00:03<00:29, 1004.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|▉         | 3219/32777 [00:03<00:28, 1026.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|█         | 3323/32777 [00:03<00:30, 957.70it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 11%|█         | 3448/32777 [00:03<00:28, 1036.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 11%|█         | 3554/32777 [00:03<00:30, 949.98it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 11%|█         | 3653/32777 [00:03<00:30, 954.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 12%|█▏        | 3785/32777 [00:03<00:27, 1046.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 12%|█▏        | 3892/32777 [00:04<00:27, 1041.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 12%|█▏        | 3998/32777 [00:04<00:30, 946.44it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 12%|█▏        | 4095/32777 [00:04<00:31, 909.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 13%|█▎        | 4201/32777 [00:04<00:30, 945.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 13%|█▎        | 4298/32777 [00:04<00:32, 869.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 13%|█▎        | 4393/32777 [00:04<00:31, 889.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 14%|█▎        | 4484/32777 [00:04<00:36, 764.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 14%|█▍        | 4590/32777 [00:04<00:34, 827.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 14%|█▍        | 4682/32777 [00:04<00:33, 848.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|█▍        | 4804/32777 [00:05<00:29, 944.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|█▍        | 4902/32777 [00:05<00:29, 950.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|█▌        | 5000/32777 [00:05<00:30, 917.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 16%|█▌        | 5094/32777 [00:05<00:31, 868.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 16%|█▌        | 5183/32777 [00:05<00:31, 864.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 16%|█▌        | 5296/32777 [00:05<00:29, 930.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 16%|█▋        | 5391/32777 [00:05<00:29, 924.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 17%|█▋        | 5487/32777 [00:05<00:29, 925.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 17%|█▋        | 5581/32777 [00:05<00:31, 876.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 17%|█▋        | 5670/32777 [00:06<00:31, 870.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 5758/32777 [00:06<00:31, 866.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 5847/32777 [00:06<00:30, 871.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 5935/32777 [00:06<00:33, 790.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 6028/32777 [00:06<00:32, 826.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 19%|█▊        | 6121/32777 [00:06<00:31, 852.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 19%|█▉        | 6224/32777 [00:06<00:29, 901.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 19%|█▉        | 6326/32777 [00:06<00:28, 927.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|█▉        | 6420/32777 [00:06<00:28, 923.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|█▉        | 6513/32777 [00:07<00:30, 861.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|██        | 6601/32777 [00:07<00:31, 824.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|██        | 6697/32777 [00:07<00:30, 856.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 21%|██        | 6784/32777 [00:07<00:30, 845.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 21%|██        | 6871/32777 [00:07<00:30, 850.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 21%|██▏       | 6996/32777 [00:07<00:26, 963.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 22%|██▏       | 7110/32777 [00:07<00:25, 1005.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 22%|██▏       | 7212/32777 [00:07<00:28, 893.50it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 22%|██▏       | 7316/32777 [00:07<00:27, 930.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 7412/32777 [00:08<00:27, 917.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 7506/32777 [00:08<00:28, 897.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 7597/32777 [00:08<00:31, 792.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 7679/32777 [00:08<00:33, 745.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 24%|██▎       | 7768/32777 [00:08<00:32, 779.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 24%|██▍       | 7852/32777 [00:08<00:31, 793.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 24%|██▍       | 7959/32777 [00:08<00:28, 869.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|██▍       | 8048/32777 [00:08<00:28, 866.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|██▍       | 8140/32777 [00:08<00:27, 880.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|██▌       | 8246/32777 [00:09<00:26, 931.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|██▌       | 8340/32777 [00:09<00:29, 827.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 26%|██▌       | 8426/32777 [00:09<00:31, 778.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 26%|██▌       | 8511/32777 [00:09<00:30, 792.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 26%|██▌       | 8592/32777 [00:09<00:31, 779.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 26%|██▋       | 8678/32777 [00:09<00:30, 793.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 27%|██▋       | 8763/32777 [00:09<00:29, 805.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 27%|██▋       | 8846/32777 [00:09<00:29, 809.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 27%|██▋       | 8947/32777 [00:09<00:27, 859.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 28%|██▊       | 9034/32777 [00:10<00:27, 862.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 28%|██▊       | 9121/32777 [00:10<00:28, 838.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 28%|██▊       | 9206/32777 [00:10<00:28, 836.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 28%|██▊       | 9290/32777 [00:10<00:29, 798.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 29%|██▊       | 9371/32777 [00:10<00:31, 753.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 29%|██▉       | 9448/32777 [00:10<00:32, 725.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 29%|██▉       | 9522/32777 [00:10<00:32, 723.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 29%|██▉       | 9595/32777 [00:10<00:34, 669.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 29%|██▉       | 9663/32777 [00:10<00:35, 656.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|██▉       | 9730/32777 [00:11<00:35, 652.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|██▉       | 9796/32777 [00:11<00:35, 639.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|███       | 9869/32777 [00:11<00:34, 664.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|███       | 9936/32777 [00:11<00:35, 648.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███       | 10012/32777 [00:11<00:33, 676.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███       | 10088/32777 [00:11<00:32, 691.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███       | 10158/32777 [00:11<00:33, 682.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███       | 10238/32777 [00:11<00:31, 712.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███▏      | 10310/32777 [00:11<00:33, 667.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▏      | 10384/32777 [00:11<00:32, 680.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▏      | 10464/32777 [00:12<00:31, 712.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▏      | 10552/32777 [00:12<00:29, 758.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▏      | 10629/32777 [00:12<00:30, 733.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 33%|███▎      | 10703/32777 [00:12<00:32, 685.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 33%|███▎      | 10778/32777 [00:12<00:31, 697.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 33%|███▎      | 10854/32777 [00:12<00:30, 713.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 33%|███▎      | 10942/32777 [00:12<00:28, 760.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 34%|███▎      | 11039/32777 [00:12<00:26, 820.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 34%|███▍      | 11122/32777 [00:12<00:28, 757.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 34%|███▍      | 11200/32777 [00:13<00:29, 725.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 34%|███▍      | 11274/32777 [00:13<00:29, 724.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|███▍      | 11348/32777 [00:13<00:31, 680.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|███▍      | 11434/32777 [00:13<00:29, 727.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|███▌      | 11508/32777 [00:13<00:31, 677.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|███▌      | 11577/32777 [00:13<00:33, 627.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 36%|███▌      | 11681/32777 [00:13<00:28, 731.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 36%|███▌      | 11757/32777 [00:13<00:28, 735.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 36%|███▌      | 11833/32777 [00:13<00:29, 721.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 36%|███▋      | 11907/32777 [00:14<00:30, 676.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 37%|███▋      | 11976/32777 [00:14<00:30, 674.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 37%|███▋      | 12046/32777 [00:14<00:30, 680.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 37%|███▋      | 12135/32777 [00:14<00:27, 739.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 37%|███▋      | 12210/32777 [00:14<00:28, 712.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 37%|███▋      | 12288/32777 [00:14<00:28, 722.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 38%|███▊      | 12361/32777 [00:14<00:29, 699.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 38%|███▊      | 12450/32777 [00:14<00:27, 748.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 38%|███▊      | 12539/32777 [00:14<00:25, 788.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 39%|███▊      | 12626/32777 [00:15<00:24, 810.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 39%|███▉      | 12708/32777 [00:15<00:25, 777.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 39%|███▉      | 12787/32777 [00:15<00:26, 760.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 39%|███▉      | 12871/32777 [00:15<00:25, 781.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|███▉      | 12989/32777 [00:15<00:22, 895.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|███▉      | 13093/32777 [00:15<00:21, 931.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|████      | 13188/32777 [00:15<00:20, 935.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 41%|████      | 13282/32777 [00:15<00:21, 886.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 41%|████      | 13372/32777 [00:15<00:23, 813.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 41%|████      | 13455/32777 [00:16<00:26, 738.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 41%|████▏     | 13539/32777 [00:16<00:25, 759.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 42%|████▏     | 13617/32777 [00:16<00:25, 751.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 42%|████▏     | 13694/32777 [00:16<00:26, 718.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 42%|████▏     | 13781/32777 [00:16<00:25, 757.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 42%|████▏     | 13875/32777 [00:16<00:23, 807.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 43%|████▎     | 13979/32777 [00:16<00:21, 867.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 43%|████▎     | 14067/32777 [00:16<00:22, 818.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 43%|████▎     | 14150/32777 [00:16<00:23, 803.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 43%|████▎     | 14232/32777 [00:17<00:24, 769.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 44%|████▎     | 14314/32777 [00:17<00:23, 782.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 44%|████▍     | 14416/32777 [00:17<00:21, 847.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 44%|████▍     | 14520/32777 [00:17<00:20, 882.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|████▍     | 14609/32777 [00:17<00:20, 879.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|████▍     | 14698/32777 [00:17<00:20, 862.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|████▌     | 14785/32777 [00:17<00:22, 807.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|████▌     | 14882/32777 [00:17<00:21, 849.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 14968/32777 [00:17<00:22, 775.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 15048/32777 [00:18<00:24, 720.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 15122/32777 [00:18<00:24, 719.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▋     | 15199/32777 [00:18<00:24, 730.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 47%|████▋     | 15274/32777 [00:18<00:23, 734.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 47%|████▋     | 15349/32777 [00:18<00:23, 733.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 47%|████▋     | 15423/32777 [00:18<00:23, 728.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 47%|████▋     | 15521/32777 [00:18<00:21, 797.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 48%|████▊     | 15602/32777 [00:18<00:22, 766.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 48%|████▊     | 15680/32777 [00:18<00:24, 709.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 48%|████▊     | 15790/32777 [00:19<00:20, 814.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 48%|████▊     | 15874/32777 [00:19<00:21, 780.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 49%|████▊     | 15958/32777 [00:19<00:21, 790.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 49%|████▉     | 16039/32777 [00:19<00:28, 580.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 49%|████▉     | 16131/32777 [00:19<00:25, 655.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 49%|████▉     | 16214/32777 [00:19<00:23, 697.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|████▉     | 16291/32777 [00:19<00:23, 696.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|████▉     | 16371/32777 [00:19<00:22, 723.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████     | 16448/32777 [00:20<00:23, 692.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████     | 16533/32777 [00:20<00:22, 733.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 51%|█████     | 16626/32777 [00:20<00:20, 780.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 51%|█████     | 16709/32777 [00:20<00:20, 794.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 51%|█████     | 16790/32777 [00:20<00:20, 781.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 52%|█████▏    | 16882/32777 [00:20<00:19, 817.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 52%|█████▏    | 16975/32777 [00:20<00:18, 849.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 52%|█████▏    | 17087/32777 [00:20<00:16, 923.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 52%|█████▏    | 17180/32777 [00:20<00:17, 905.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 53%|█████▎    | 17272/32777 [00:20<00:19, 795.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 53%|█████▎    | 17355/32777 [00:21<00:19, 792.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 53%|█████▎    | 17437/32777 [00:21<00:20, 747.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 53%|█████▎    | 17514/32777 [00:21<00:20, 737.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▎    | 17589/32777 [00:21<00:21, 716.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▍    | 17662/32777 [00:21<00:22, 666.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▍    | 17730/32777 [00:21<00:23, 649.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▍    | 17796/32777 [00:21<00:23, 646.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▍    | 17866/32777 [00:21<00:22, 659.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▍    | 17951/32777 [00:21<00:20, 710.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▌    | 18031/32777 [00:22<00:20, 731.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▌    | 18105/32777 [00:22<00:21, 681.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▌    | 18175/32777 [00:22<00:23, 633.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 56%|█████▌    | 18256/32777 [00:22<00:21, 678.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 56%|█████▌    | 18327/32777 [00:22<00:21, 679.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 56%|█████▌    | 18396/32777 [00:22<00:21, 673.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 56%|█████▋    | 18464/32777 [00:22<00:21, 672.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 57%|█████▋    | 18548/32777 [00:22<00:19, 719.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 57%|█████▋    | 18647/32777 [00:22<00:17, 792.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 57%|█████▋    | 18727/32777 [00:23<00:18, 766.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 57%|█████▋    | 18806/32777 [00:23<00:18, 771.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 58%|█████▊    | 18884/32777 [00:23<00:18, 763.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 58%|█████▊    | 18967/32777 [00:23<00:17, 775.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 58%|█████▊    | 19045/32777 [00:23<00:18, 756.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 58%|█████▊    | 19135/32777 [00:23<00:17, 792.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 59%|█████▊    | 19219/32777 [00:23<00:16, 802.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 59%|█████▉    | 19300/32777 [00:23<00:16, 797.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 59%|█████▉    | 19380/32777 [00:23<00:16, 788.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 59%|█████▉    | 19459/32777 [00:23<00:16, 787.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|█████▉    | 19538/32777 [00:24<00:16, 784.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|█████▉    | 19617/32777 [00:24<00:18, 724.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████    | 19711/32777 [00:24<00:16, 779.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████    | 19794/32777 [00:24<00:16, 782.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 61%|██████    | 19873/32777 [00:24<00:16, 771.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 61%|██████    | 19951/32777 [00:24<00:17, 748.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 61%|██████    | 20027/32777 [00:24<00:17, 717.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 61%|██████▏   | 20100/32777 [00:24<00:18, 677.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 62%|██████▏   | 20202/32777 [00:24<00:16, 768.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 62%|██████▏   | 20300/32777 [00:25<00:15, 815.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 62%|██████▏   | 20383/32777 [00:25<00:15, 803.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 62%|██████▏   | 20465/32777 [00:25<00:16, 751.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 63%|██████▎   | 20553/32777 [00:25<00:15, 781.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 63%|██████▎   | 20648/32777 [00:25<00:14, 819.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 63%|██████▎   | 20759/32777 [00:25<00:13, 890.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 64%|██████▎   | 20849/32777 [00:25<00:13, 860.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 64%|██████▍   | 20936/32777 [00:25<00:15, 785.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 64%|██████▍   | 21029/32777 [00:25<00:14, 817.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 64%|██████▍   | 21113/32777 [00:26<00:14, 802.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|██████▍   | 21212/32777 [00:26<00:13, 847.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|██████▍   | 21298/32777 [00:26<00:13, 841.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|██████▌   | 21394/32777 [00:26<00:13, 869.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 66%|██████▌   | 21511/32777 [00:26<00:11, 952.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 66%|██████▌   | 21623/32777 [00:26<00:11, 999.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 66%|██████▋   | 21724/32777 [00:26<00:11, 984.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 67%|██████▋   | 21823/32777 [00:26<00:11, 930.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 67%|██████▋   | 21917/32777 [00:26<00:13, 825.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 67%|██████▋   | 22003/32777 [00:27<00:13, 825.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 67%|██████▋   | 22088/32777 [00:27<00:12, 830.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 68%|██████▊   | 22173/32777 [00:27<00:13, 806.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 68%|██████▊   | 22255/32777 [00:27<00:13, 793.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 68%|██████▊   | 22364/32777 [00:27<00:11, 876.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 69%|██████▊   | 22453/32777 [00:27<00:12, 827.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 69%|██████▉   | 22563/32777 [00:27<00:11, 896.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 69%|██████▉   | 22660/32777 [00:27<00:11, 916.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 69%|██████▉   | 22758/32777 [00:27<00:10, 934.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|██████▉   | 22869/32777 [00:28<00:10, 983.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|███████   | 22972/32777 [00:28<00:09, 989.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|███████   | 23074/32777 [00:28<00:09, 991.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 71%|███████   | 23174/32777 [00:28<00:09, 988.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 71%|███████   | 23274/32777 [00:28<00:10, 924.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 71%|███████▏  | 23371/32777 [00:28<00:10, 935.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 72%|███████▏  | 23466/32777 [00:28<00:10, 903.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 72%|███████▏  | 23585/32777 [00:28<00:09, 969.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 72%|███████▏  | 23683/32777 [00:28<00:09, 926.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 73%|███████▎  | 23777/32777 [00:29<00:09, 902.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 73%|███████▎  | 23892/32777 [00:29<00:09, 969.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 73%|███████▎  | 23990/32777 [00:29<00:09, 926.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 73%|███████▎  | 24084/32777 [00:29<00:09, 902.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 74%|███████▍  | 24175/32777 [00:29<00:10, 833.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 74%|███████▍  | 24263/32777 [00:29<00:10, 840.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 74%|███████▍  | 24348/32777 [00:29<00:10, 827.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|███████▍  | 24445/32777 [00:29<00:09, 860.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|███████▍  | 24534/32777 [00:29<00:09, 865.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|███████▌  | 24634/32777 [00:29<00:09, 901.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|███████▌  | 24728/32777 [00:30<00:08, 911.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 76%|███████▌  | 24820/32777 [00:30<00:08, 909.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 76%|███████▌  | 24912/32777 [00:30<00:09, 860.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 76%|███████▋  | 25005/32777 [00:30<00:08, 878.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 77%|███████▋  | 25101/32777 [00:30<00:08, 898.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 77%|███████▋  | 25227/32777 [00:30<00:07, 1000.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 77%|███████▋  | 25341/32777 [00:30<00:07, 1036.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 78%|███████▊  | 25446/32777 [00:30<00:07, 1011.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 78%|███████▊  | 25569/32777 [00:30<00:06, 1073.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 78%|███████▊  | 25677/32777 [00:31<00:07, 974.35it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 79%|███████▊  | 25777/32777 [00:31<00:07, 948.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 79%|███████▉  | 25876/32777 [00:31<00:07, 958.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 79%|███████▉  | 25973/32777 [00:31<00:07, 929.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|███████▉  | 26067/32777 [00:31<00:07, 852.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|███████▉  | 26187/32777 [00:31<00:06, 941.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|████████  | 26284/32777 [00:31<00:06, 941.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|████████  | 26380/32777 [00:31<00:06, 943.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 81%|████████  | 26476/32777 [00:31<00:06, 918.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 81%|████████  | 26571/32777 [00:32<00:06, 925.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 81%|████████▏ | 26671/32777 [00:32<00:06, 942.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 82%|████████▏ | 26766/32777 [00:32<00:06, 940.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 82%|████████▏ | 26861/32777 [00:32<00:06, 915.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 82%|████████▏ | 26958/32777 [00:32<00:06, 928.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 83%|████████▎ | 27052/32777 [00:32<00:06, 896.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 83%|████████▎ | 27142/32777 [00:32<00:06, 866.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 83%|████████▎ | 27229/32777 [00:32<00:06, 836.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 83%|████████▎ | 27315/32777 [00:32<00:06, 841.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 84%|████████▎ | 27400/32777 [00:32<00:06, 837.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 84%|████████▍ | 27484/32777 [00:33<00:06, 837.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 84%|████████▍ | 27584/32777 [00:33<00:05, 877.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 84%|████████▍ | 27684/32777 [00:33<00:05, 913.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 85%|████████▍ | 27776/32777 [00:33<00:05, 906.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 85%|████████▌ | 27882/32777 [00:33<00:05, 945.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 85%|████████▌ | 27980/32777 [00:33<00:05, 954.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 86%|████████▌ | 28094/32777 [00:33<00:04, 1009.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 86%|████████▌ | 28196/32777 [00:33<00:05, 895.26it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 86%|████████▋ | 28288/32777 [00:33<00:05, 867.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 87%|████████▋ | 28377/32777 [00:34<00:05, 783.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 87%|████████▋ | 28461/32777 [00:34<00:05, 797.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 87%|████████▋ | 28543/32777 [00:34<00:05, 795.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 87%|████████▋ | 28630/32777 [00:34<00:05, 814.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 88%|████████▊ | 28716/32777 [00:34<00:04, 823.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 88%|████████▊ | 28800/32777 [00:34<00:04, 824.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 88%|████████▊ | 28891/32777 [00:34<00:04, 848.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 88%|████████▊ | 28977/32777 [00:34<00:04, 814.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 89%|████████▊ | 29061/32777 [00:34<00:04, 814.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 89%|████████▉ | 29173/32777 [00:35<00:04, 898.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 89%|████████▉ | 29273/32777 [00:35<00:03, 925.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|████████▉ | 29367/32777 [00:35<00:03, 897.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|████████▉ | 29458/32777 [00:35<00:03, 870.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████ | 29569/32777 [00:35<00:03, 938.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 91%|█████████ | 29664/32777 [00:35<00:03, 923.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 91%|█████████ | 29757/32777 [00:35<00:03, 881.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 91%|█████████ | 29846/32777 [00:35<00:03, 850.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 91%|█████████▏| 29939/32777 [00:35<00:03, 872.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 92%|█████████▏| 30048/32777 [00:35<00:02, 931.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 92%|█████████▏| 30146/32777 [00:36<00:02, 929.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 92%|█████████▏| 30240/32777 [00:36<00:02, 894.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 93%|█████████▎| 30358/32777 [00:36<00:02, 974.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 93%|█████████▎| 30457/32777 [00:36<00:02, 913.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 93%|█████████▎| 30550/32777 [00:36<00:02, 863.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 93%|█████████▎| 30644/32777 [00:36<00:02, 882.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 94%|█████████▍| 30756/32777 [00:36<00:02, 946.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 94%|█████████▍| 30859/32777 [00:36<00:01, 965.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 94%|█████████▍| 30957/32777 [00:36<00:01, 939.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████▍| 31052/32777 [00:37<00:01, 919.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████▌| 31148/32777 [00:37<00:01, 927.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████▌| 31242/32777 [00:37<00:01, 927.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 96%|█████████▌| 31344/32777 [00:37<00:01, 946.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 96%|█████████▌| 31439/32777 [00:37<00:01, 937.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 96%|█████████▋| 31566/32777 [00:37<00:01, 1031.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 97%|█████████▋| 31670/32777 [00:37<00:01, 899.73it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 97%|█████████▋| 31771/32777 [00:37<00:01, 928.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 97%|█████████▋| 31867/32777 [00:37<00:00, 913.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 98%|█████████▊| 31961/32777 [00:38<00:00, 895.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 98%|█████████▊| 32056/32777 [00:38<00:00, 903.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 98%|█████████▊| 32148/32777 [00:38<00:00, 896.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 98%|█████████▊| 32246/32777 [00:38<00:00, 910.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 99%|█████████▊| 32356/32777 [00:38<00:00, 957.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 99%|█████████▉| 32485/32777 [00:38<00:00, 1052.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 99%|█████████▉| 32610/32777 [00:38<00:00, 1101.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "100%|█████████▉| 32721/32777 [00:38<00:00, 1060.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "100%|██████████| 32777/32777 [00:38<00:00, 843.76it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (64800,)\n",
      "contexts.shape: (64800, 5)\n",
      "labels.shape: (64800, 5)\n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=SEED)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97PqsusOFEpc"
   },
   "source": [
    "### Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jnFVySViQTj"
   },
   "source": [
    "To perform efficient batching for the potentially large number of training examples, use the `tf.data.Dataset` API. After this step, you would have a `tf.data.Dataset` object of `(target_word, context_word), (label)` elements to train your word2vec model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:20.090676Z",
     "iopub.status.busy": "2023-12-07T12:20:20.089982Z",
     "iopub.status.idle": "2023-12-07T12:20:20.107254Z",
     "shell.execute_reply": "2023-12-07T12:20:20.106584Z"
    },
    "id": "nbu8PxPSnVY2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyrNX6Fs6K3F"
   },
   "source": [
    "Apply `Dataset.cache` and `Dataset.prefetch` to improve performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:20.111005Z",
     "iopub.status.busy": "2023-12-07T12:20:20.110525Z",
     "iopub.status.idle": "2023-12-07T12:20:20.117911Z",
     "shell.execute_reply": "2023-12-07T12:20:20.117259Z"
    },
    "id": "Y5Ueg6bcFPVL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S-CmUMszyEf"
   },
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQFqaBMPwBqC"
   },
   "source": [
    "The word2vec model can be implemented as a classifier to distinguish between true context words from skip-grams and false context words obtained through negative sampling. You can perform a dot product multiplication between the embeddings of target and context words to obtain predictions for labels and compute the loss function against true labels in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oc7kTbiwD9sy"
   },
   "source": [
    "### Subclassed word2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jvr9pM1G1sQN"
   },
   "source": [
    "Use the [Keras Subclassing API](https://www.tensorflow.org/guide/keras/custom_layers_and_models) to define your word2vec model with the following layers:\n",
    "\n",
    "* `target_embedding`: A `tf.keras.layers.Embedding` layer, which looks up the embedding of a word when it appears as a target word. The number of parameters in this layer are `(vocab_size * embedding_dim)`.\n",
    "* `context_embedding`: Another `tf.keras.layers.Embedding` layer, which looks up the embedding of a word when it appears as a context word. The number of parameters in this layer are the same as those in `target_embedding`, i.e. `(vocab_size * embedding_dim)`.\n",
    "* `dots`: A `tf.keras.layers.Dot` layer that computes the dot product of target and context embeddings from a training pair.\n",
    "* `flatten`: A `tf.keras.layers.Flatten` layer to flatten the results of `dots` layer into logits.\n",
    "\n",
    "With the subclassed model, you can define the `call()` function that accepts `(target, context)` pairs which can then be passed into their corresponding embedding layer. Reshape the `context_embedding` to perform a dot product with `target_embedding` and return the flattened result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiAwuIqqw7-7"
   },
   "source": [
    "Key point: The `target_embedding` and `context_embedding` layers can be shared as well. You could also use a concatenation of both embeddings as the final word2vec embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:20.121679Z",
     "iopub.status.busy": "2023-12-07T12:20:20.121413Z",
     "iopub.status.idle": "2023-12-07T12:20:20.127047Z",
     "shell.execute_reply": "2023-12-07T12:20:20.126435Z"
    },
    "id": "i9ec-sS6xd8Z"
   },
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                       embedding_dim,\n",
    "                                       input_length=num_ns+1)\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
    "    # context: (batch, context)\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    # target: (batch,)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    # word_emb: (batch, embed)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    # context_emb: (batch, context, embed)\n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "    # dots: (batch, context)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RLKz9LFECXu"
   },
   "source": [
    "### Define loss function and compile model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3Md-9QanqBM"
   },
   "source": [
    "For simplicity, you can use `tf.keras.losses.CategoricalCrossEntropy` as an alternative to the negative sampling loss. If you would like to write your own custom loss function, you can also do so as follows:\n",
    "\n",
    "``` python\n",
    "def custom_loss(x_logit, y_true):\n",
    "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)\n",
    "```\n",
    "\n",
    "It's time to build your model! Instantiate your word2vec class with an embedding dimension of 128 (you could experiment with different values). Compile the model with the `tf.keras.optimizers.Adam` optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:20.130349Z",
     "iopub.status.busy": "2023-12-07T12:20:20.129949Z",
     "iopub.status.idle": "2023-12-07T12:20:20.153408Z",
     "shell.execute_reply": "2023-12-07T12:20:20.152768Z"
    },
    "id": "ekQg_KbWnnmQ"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3MUMrluqNX2"
   },
   "source": [
    "Also define a callback to log training statistics for TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:20.157172Z",
     "iopub.status.busy": "2023-12-07T12:20:20.156503Z",
     "iopub.status.idle": "2023-12-07T12:20:20.160522Z",
     "shell.execute_reply": "2023-12-07T12:20:20.159931Z"
    },
    "id": "9d-ftBCeEZIR"
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5wEBotlGZ7B"
   },
   "source": [
    "Train the model on the `dataset` for some number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:20.163918Z",
     "iopub.status.busy": "2023-12-07T12:20:20.163670Z",
     "iopub.status.idle": "2023-12-07T12:20:30.513238Z",
     "shell.execute_reply": "2023-12-07T12:20:30.512506Z"
    },
    "id": "gmC1BJalEZIY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 1:10 - loss: 1.6101 - accuracy: 0.1934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701951621.205941   11367 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 2/63 [..............................] - ETA: 6s - loss: 1.6098 - accuracy: 0.1943  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 3/63 [>.............................] - ETA: 6s - loss: 1.6097 - accuracy: 0.1992"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 4/63 [>.............................] - ETA: 5s - loss: 1.6097 - accuracy: 0.2026"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 5/63 [=>............................] - ETA: 7s - loss: 1.6096 - accuracy: 0.1998"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 6/63 [=>............................] - ETA: 7s - loss: 1.6095 - accuracy: 0.2017"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 7/63 [==>...........................] - ETA: 7s - loss: 1.6095 - accuracy: 0.2017"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 8/63 [==>...........................] - ETA: 6s - loss: 1.6094 - accuracy: 0.2041"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 9/63 [===>..........................] - ETA: 6s - loss: 1.6094 - accuracy: 0.2045"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "10/63 [===>..........................] - ETA: 6s - loss: 1.6094 - accuracy: 0.2055"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "11/63 [====>.........................] - ETA: 6s - loss: 1.6093 - accuracy: 0.2054"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "12/63 [====>.........................] - ETA: 6s - loss: 1.6093 - accuracy: 0.2056"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "13/63 [=====>........................] - ETA: 6s - loss: 1.6093 - accuracy: 0.2055"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "14/63 [=====>........................] - ETA: 6s - loss: 1.6093 - accuracy: 0.2070"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "15/63 [======>.......................] - ETA: 5s - loss: 1.6092 - accuracy: 0.2072"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "16/63 [======>.......................] - ETA: 5s - loss: 1.6093 - accuracy: 0.2063"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "17/63 [=======>......................] - ETA: 5s - loss: 1.6093 - accuracy: 0.2067"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "18/63 [=======>......................] - ETA: 5s - loss: 1.6092 - accuracy: 0.2079"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "19/63 [========>.....................] - ETA: 5s - loss: 1.6092 - accuracy: 0.2100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 5s - loss: 1.6091 - accuracy: 0.2113"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "21/63 [=========>....................] - ETA: 4s - loss: 1.6091 - accuracy: 0.2115"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "22/63 [=========>....................] - ETA: 4s - loss: 1.6091 - accuracy: 0.2120"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "23/63 [=========>....................] - ETA: 4s - loss: 1.6091 - accuracy: 0.2120"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "25/63 [==========>...................] - ETA: 4s - loss: 1.6090 - accuracy: 0.2137"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "26/63 [===========>..................] - ETA: 4s - loss: 1.6090 - accuracy: 0.2145"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "27/63 [===========>..................] - ETA: 4s - loss: 1.6090 - accuracy: 0.2159"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "28/63 [============>.................] - ETA: 3s - loss: 1.6090 - accuracy: 0.2162"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "29/63 [============>.................] - ETA: 3s - loss: 1.6090 - accuracy: 0.2167"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "31/63 [=============>................] - ETA: 3s - loss: 1.6089 - accuracy: 0.2176"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "32/63 [==============>...............] - ETA: 3s - loss: 1.6089 - accuracy: 0.2183"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "33/63 [==============>...............] - ETA: 3s - loss: 1.6089 - accuracy: 0.2190"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "34/63 [===============>..............] - ETA: 3s - loss: 1.6089 - accuracy: 0.2204"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "35/63 [===============>..............] - ETA: 2s - loss: 1.6088 - accuracy: 0.2205"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "36/63 [================>.............] - ETA: 2s - loss: 1.6088 - accuracy: 0.2207"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "37/63 [================>.............] - ETA: 2s - loss: 1.6088 - accuracy: 0.2209"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "40/63 [==================>...........] - ETA: 2s - loss: 1.6088 - accuracy: 0.2222"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "44/63 [===================>..........] - ETA: 1s - loss: 1.6087 - accuracy: 0.2236"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "45/63 [====================>.........] - ETA: 1s - loss: 1.6087 - accuracy: 0.2242"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "46/63 [====================>.........] - ETA: 1s - loss: 1.6086 - accuracy: 0.2249"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "47/63 [=====================>........] - ETA: 1s - loss: 1.6086 - accuracy: 0.2255"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "49/63 [======================>.......] - ETA: 1s - loss: 1.6086 - accuracy: 0.2265"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "50/63 [======================>.......] - ETA: 1s - loss: 1.6085 - accuracy: 0.2266"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "51/63 [=======================>......] - ETA: 1s - loss: 1.6085 - accuracy: 0.2262"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 1.6085 - accuracy: 0.2271"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 1.6084 - accuracy: 0.2278"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 1.6083 - accuracy: 0.2300"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 1.6083 - accuracy: 0.2305"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "61/63 [============================>.] - ETA: 0s - loss: 1.6083 - accuracy: 0.2311"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.6082 - accuracy: 0.2317"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6082 - accuracy: 0.2319"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 7s 93ms/step - loss: 1.6082 - accuracy: 0.2319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.5907 - accuracy: 0.7295"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "19/63 [========>.....................] - ETA: 0s - loss: 1.5939 - accuracy: 0.5984"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "38/63 [=================>............] - ETA: 0s - loss: 1.5924 - accuracy: 0.5717"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 1.5902 - accuracy: 0.5576"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5890 - accuracy: 0.5530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.5585 - accuracy: 0.7451"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "19/63 [========>.....................] - ETA: 0s - loss: 1.5586 - accuracy: 0.6627"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "38/63 [=================>............] - ETA: 0s - loss: 1.5523 - accuracy: 0.6318"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 1.5448 - accuracy: 0.6144"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5420 - accuracy: 0.6082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.4866 - accuracy: 0.6504"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 1.4838 - accuracy: 0.6061"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "38/63 [=================>............] - ETA: 0s - loss: 1.4751 - accuracy: 0.5895"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 1.4650 - accuracy: 0.5828"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4606 - accuracy: 0.5798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.3869 - accuracy: 0.6143"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 1.3857 - accuracy: 0.5955"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "38/63 [=================>............] - ETA: 0s - loss: 1.3779 - accuracy: 0.5856"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 1.3672 - accuracy: 0.5856"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3634 - accuracy: 0.5851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.2828 - accuracy: 0.6230"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 1.2855 - accuracy: 0.6137"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "40/63 [==================>...........] - ETA: 0s - loss: 1.2788 - accuracy: 0.6070"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 1.2688 - accuracy: 0.6105"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2667 - accuracy: 0.6103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.1856 - accuracy: 0.6582"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 1.1916 - accuracy: 0.6459"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "39/63 [=================>............] - ETA: 0s - loss: 1.1868 - accuracy: 0.6415"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 1.1784 - accuracy: 0.6445"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1758 - accuracy: 0.6449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.0971 - accuracy: 0.6982"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "21/63 [=========>....................] - ETA: 0s - loss: 1.1048 - accuracy: 0.6783"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "41/63 [==================>...........] - ETA: 0s - loss: 1.1009 - accuracy: 0.6749"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 1.0923 - accuracy: 0.6794"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0912 - accuracy: 0.6793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.0163 - accuracy: 0.7227"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "21/63 [=========>....................] - ETA: 0s - loss: 1.0245 - accuracy: 0.7092"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "40/63 [==================>...........] - ETA: 0s - loss: 1.0211 - accuracy: 0.7070"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 1.0134 - accuracy: 0.7105"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0125 - accuracy: 0.7105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.9420 - accuracy: 0.7510"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "21/63 [=========>....................] - ETA: 0s - loss: 0.9501 - accuracy: 0.7391"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "40/63 [==================>...........] - ETA: 0s - loss: 0.9470 - accuracy: 0.7367"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.9411 - accuracy: 0.7388"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9393 - accuracy: 0.7392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.8735 - accuracy: 0.7783"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "21/63 [=========>....................] - ETA: 0s - loss: 0.8812 - accuracy: 0.7634"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "40/63 [==================>...........] - ETA: 0s - loss: 0.8783 - accuracy: 0.7626"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.8725 - accuracy: 0.7652"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8715 - accuracy: 0.7653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.8105 - accuracy: 0.7969"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 0.8179 - accuracy: 0.7864"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.8146 - accuracy: 0.7865"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.8103 - accuracy: 0.7877"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8089 - accuracy: 0.7878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.7526 - accuracy: 0.8115"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "21/63 [=========>....................] - ETA: 0s - loss: 0.7592 - accuracy: 0.8065"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "41/63 [==================>...........] - ETA: 0s - loss: 0.7567 - accuracy: 0.8070"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.7517 - accuracy: 0.8083"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.6995 - accuracy: 0.8330"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 0.7059 - accuracy: 0.8244"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.7027 - accuracy: 0.8249"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.6996 - accuracy: 0.8253"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.8256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.6511 - accuracy: 0.8477"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 0.6570 - accuracy: 0.8397"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.6538 - accuracy: 0.8403"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.6513 - accuracy: 0.8406"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.8409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.6069 - accuracy: 0.8613"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 0.6124 - accuracy: 0.8533"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.6092 - accuracy: 0.8539"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.6072 - accuracy: 0.8543"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.8544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.5668 - accuracy: 0.8770"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 0.5719 - accuracy: 0.8653"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.5686 - accuracy: 0.8662"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.5671 - accuracy: 0.8667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.8668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.5303 - accuracy: 0.8838"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 0.5350 - accuracy: 0.8755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.5318 - accuracy: 0.8768"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.5306 - accuracy: 0.8775"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.8774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.4971 - accuracy: 0.8965"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "21/63 [=========>....................] - ETA: 0s - loss: 0.5011 - accuracy: 0.8861"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "41/63 [==================>...........] - ETA: 0s - loss: 0.4990 - accuracy: 0.8863"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.4971 - accuracy: 0.8871"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.8868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.4670 - accuracy: 0.9043"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "20/63 [========>.....................] - ETA: 0s - loss: 0.4712 - accuracy: 0.8940"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "38/63 [=================>............] - ETA: 0s - loss: 0.4678 - accuracy: 0.8959"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.4674 - accuracy: 0.8959"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.8956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f37b03562b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wze38jG57XvZ"
   },
   "source": [
    "TensorBoard now shows the word2vec model's accuracy and loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22E9eqS55rgz"
   },
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awF3iRQCZOLj"
   },
   "source": [
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/word2vec_tensorboard.png\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaDW2tIIz8fL"
   },
   "source": [
    "## Embedding lookup and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp5rv01WG2YA"
   },
   "source": [
    "Obtain the weights from the model using `Model.get_layer` and `Layer.get_weights`. The `TextVectorization.get_vocabulary` function provides the vocabulary to build a metadata file with one token per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:30.516990Z",
     "iopub.status.busy": "2023-12-07T12:20:30.516655Z",
     "iopub.status.idle": "2023-12-07T12:20:30.529314Z",
     "shell.execute_reply": "2023-12-07T12:20:30.528606Z"
    },
    "id": "_Uamp1YH8RzU"
   },
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWzdmUzS8Sl4"
   },
   "source": [
    "Create and save the vectors and metadata files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:30.532660Z",
     "iopub.status.busy": "2023-12-07T12:20:30.532393Z",
     "iopub.status.idle": "2023-12-07T12:20:30.841834Z",
     "shell.execute_reply": "2023-12-07T12:20:30.841159Z"
    },
    "id": "VLIahl9s53XT"
   },
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T8KcThhIU8-"
   },
   "source": [
    "Download the `vectors.tsv` and `metadata.tsv` to analyze the obtained embeddings in the [Embedding Projector](https://projector.tensorflow.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:20:30.845950Z",
     "iopub.status.busy": "2023-12-07T12:20:30.845356Z",
     "iopub.status.idle": "2023-12-07T12:20:30.849070Z",
     "shell.execute_reply": "2023-12-07T12:20:30.848450Z"
    },
    "id": "lUsjQOKMIV2z"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import files\n",
    "  files.download('vectors.tsv')\n",
    "  files.download('metadata.tsv')\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iS_uMeMw3Xpj"
   },
   "source": [
    "## Next steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSgAZpwF5xF_"
   },
   "source": [
    "This tutorial has shown you how to implement a skip-gram word2vec model with negative sampling from scratch and visualize the obtained word embeddings.\n",
    "\n",
    "* To learn more about word vectors and their mathematical representations, refer to these [notes](https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf).\n",
    "\n",
    "* To learn more about advanced text processing, read the [Transformer model for language understanding](https://www.tensorflow.org/tutorials/text/transformer) tutorial.\n",
    "\n",
    "* If you’re interested in pre-trained embedding models, you may also be interested in [Exploring the TF-Hub CORD-19 Swivel Embeddings](https://www.tensorflow.org/hub/tutorials/cord_19_embeddings_keras), or the [Multilingual Universal Sentence Encoder](https://www.tensorflow.org/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder).\n",
    "\n",
    "* You may also like to train the model on a new dataset (there are many available in [TensorFlow Datasets](https://www.tensorflow.org/datasets)).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "word2vec.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
